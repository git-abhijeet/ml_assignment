{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edc0880",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals & Manual Custom ANN\n",
    "\n",
    "## Assignment: Tensor Creation and Operations\n",
    "\n",
    "This notebook demonstrates basic PyTorch operations without using `torch.nn` or `torch.nn.Module`.\n",
    "\n",
    "**Objectives:**\n",
    "1. Create tensors A and B\n",
    "2. Perform matrix multiplication\n",
    "3. Perform element-wise addition\n",
    "4. Move tensors to GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b2b10e",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "Import PyTorch and check for GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80ebfc",
   "metadata": {},
   "source": [
    "## Step 2: Create Tensors A and B\n",
    "\n",
    "Create two tensors with specified dimensions:\n",
    "- A: 3x2 tensor with random values\n",
    "- B: 2x3 tensor with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b764ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create tensor A (3x2)\n",
    "A = torch.randn(3, 2)\n",
    "print(\"Tensor A (3x2):\")\n",
    "print(A)\n",
    "print(f\"Shape of A: {A.shape}\")\n",
    "print(f\"Data type of A: {A.dtype}\")\n",
    "print()\n",
    "\n",
    "# Create tensor B (2x3)\n",
    "B = torch.randn(2, 3)\n",
    "print(\"Tensor B (2x3):\")\n",
    "print(B)\n",
    "print(f\"Shape of B: {B.shape}\")\n",
    "print(f\"Data type of B: {B.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb52e5",
   "metadata": {},
   "source": [
    "## Step 3: Matrix Multiplication\n",
    "\n",
    "Compute matrix multiplication: C = A @ B\n",
    "\n",
    "Since A is 3x2 and B is 2x3, the result C will be 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d01c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication\n",
    "C = A @ B  # Equivalent to torch.matmul(A, B)\n",
    "\n",
    "print(\"Matrix Multiplication Result (C = A @ B):\")\n",
    "print(C)\n",
    "print(f\"Shape of C: {C.shape}\")\n",
    "print()\n",
    "\n",
    "# Alternative ways to perform matrix multiplication\n",
    "print(\"Verification using torch.matmul():\")\n",
    "C_alt = torch.matmul(A, B)\n",
    "print(f\"Results are equal: {torch.allclose(C, C_alt)}\")\n",
    "print()\n",
    "\n",
    "print(\"Verification using torch.mm():\")\n",
    "C_alt2 = torch.mm(A, B)\n",
    "print(f\"Results are equal: {torch.allclose(C, C_alt2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f613416",
   "metadata": {},
   "source": [
    "## Step 4: Element-wise Addition\n",
    "\n",
    "Compute element-wise addition: D = A + torch.ones_like(A)\n",
    "\n",
    "This adds 1 to each element of tensor A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14836e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of ones with the same shape as A\n",
    "ones_tensor = torch.ones_like(A)\n",
    "print(\"Ones tensor (same shape as A):\")\n",
    "print(ones_tensor)\n",
    "print()\n",
    "\n",
    "# Perform element-wise addition\n",
    "D = A + ones_tensor\n",
    "\n",
    "print(\"Element-wise Addition Result (D = A + ones):\")\n",
    "print(\"Original A:\")\n",
    "print(A)\n",
    "print(\"After adding ones (D):\")\n",
    "print(D)\n",
    "print(f\"Shape of D: {D.shape}\")\n",
    "print()\n",
    "\n",
    "# Verify the operation\n",
    "print(\"Verification - checking if each element increased by 1:\")\n",
    "difference = D - A\n",
    "print(f\"Difference (should be all ones): \\n{difference}\")\n",
    "print(f\"All differences equal to 1: {torch.allclose(difference, torch.ones_like(A))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2362c5",
   "metadata": {},
   "source": [
    "## Step 5: Move Tensors to GPU (if available)\n",
    "\n",
    "Move the result tensor C to GPU if CUDA is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensor C to the appropriate device (GPU if available, CPU otherwise)\n",
    "C_device = C.to(device)\n",
    "\n",
    "print(f\"Original C device: {C.device}\")\n",
    "print(f\"C after moving to {device}: {C_device.device}\")\n",
    "print()\n",
    "\n",
    "print(\"Tensor C on target device:\")\n",
    "print(C_device)\n",
    "print(f\"C is on device: {C_device.device}\")\n",
    "print()\n",
    "\n",
    "# Also move A and B to the device for completeness\n",
    "A_device = A.to(device)\n",
    "B_device = B.to(device)\n",
    "D_device = D.to(device)\n",
    "\n",
    "print(\"All tensors moved to device:\")\n",
    "print(f\"A is on device: {A_device.device}\")\n",
    "print(f\"B is on device: {B_device.device}\")\n",
    "print(f\"C is on device: {C_device.device}\")\n",
    "print(f\"D is on device: {D_device.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90360a92",
   "metadata": {},
   "source": [
    "## Step 6: Additional Tensor Operations\n",
    "\n",
    "Let's explore some additional tensor operations to demonstrate PyTorch fundamentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor statistics\n",
    "print(\"Tensor Statistics:\")\n",
    "print(f\"A - Mean: {A.mean():.4f}, Std: {A.std():.4f}, Min: {A.min():.4f}, Max: {A.max():.4f}\")\n",
    "print(f\"B - Mean: {B.mean():.4f}, Std: {B.std():.4f}, Min: {B.min():.4f}, Max: {B.max():.4f}\")\n",
    "print(f\"C - Mean: {C.mean():.4f}, Std: {C.std():.4f}, Min: {C.min():.4f}, Max: {C.max():.4f}\")\n",
    "print()\n",
    "\n",
    "# Tensor reshaping\n",
    "print(\"Tensor Reshaping:\")\n",
    "A_flattened = A.flatten()\n",
    "print(f\"A flattened shape: {A_flattened.shape}\")\n",
    "print(f\"A flattened: {A_flattened}\")\n",
    "print()\n",
    "\n",
    "# Tensor indexing\n",
    "print(\"Tensor Indexing:\")\n",
    "print(f\"A[0, 0] = {A[0, 0]:.4f}\")\n",
    "print(f\"A[1, :] = {A[1, :]}\")\n",
    "print(f\"A[:, 1] = {A[:, 1]}\")\n",
    "print()\n",
    "\n",
    "# Element-wise operations\n",
    "print(\"Element-wise Operations:\")\n",
    "A_squared = A ** 2\n",
    "print(f\"A squared: \\n{A_squared}\")\n",
    "print()\n",
    "\n",
    "A_exp = torch.exp(A)\n",
    "print(f\"A exponential: \\n{A_exp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40587bb1",
   "metadata": {},
   "source": [
    "## Step 7: Summary of Results\n",
    "\n",
    "Display the final results in the format similar to the expected sample output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "print(f\"A: {A}\")\n",
    "print()\n",
    "print(f\"B: {B}\")\n",
    "print()\n",
    "print(f\"C (A @ B): {C}\")\n",
    "print()\n",
    "print(f\"D (A + ones): {D}\")\n",
    "print()\n",
    "print(f\"C is on device: {C_device.device}\")\n",
    "print()\n",
    "\n",
    "# Memory usage information\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"GPU Memory Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(\"Running on CPU - No GPU memory usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8aca0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook successfully demonstrates:\n",
    "\n",
    "1. **Tensor Creation**: Created tensors A (3×2) and B (2×3) using `torch.randn()`\n",
    "2. **Matrix Multiplication**: Computed C = A @ B resulting in a 3×3 tensor\n",
    "3. **Element-wise Addition**: Computed D = A + ones, adding 1 to each element of A\n",
    "4. **Device Management**: Moved tensors to GPU if available, otherwise used CPU\n",
    "5. **Additional Operations**: Explored tensor statistics, reshaping, indexing, and element-wise operations\n",
    "\n",
    "All operations were performed using basic PyTorch operations without `torch.nn` or `torch.nn.Module` as required.\n",
    "\n",
    "The results demonstrate fundamental PyTorch tensor operations that form the building blocks for more complex deep learning models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
