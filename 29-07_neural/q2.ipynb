{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85acd5a",
   "metadata": {},
   "source": [
    "# Q2: Two-Layer Neural Network with Random Inputs\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Generate a 2-layer neural network with the following:\n",
    "- 3 random input values (x1, x2, x3)\n",
    "- First layer: 2 neurons with random weights and biases\n",
    "- Second layer: 1 output neuron with random weights and bias\n",
    "- Use the sigmoid activation at each layer\n",
    "- Compute the final output of the network\n",
    "\n",
    "## Requirements\n",
    "- Use `random.uniform(-1, 1)` to generate inputs, weights, and biases\n",
    "- Print all values and intermediate outputs\n",
    "- Show detailed calculations for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad69b4a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import the necessary libraries including random and math for generating random parameters and mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"random module: for generating random values\")\n",
    "print(\"math module: for mathematical operations including exponential function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e8bea",
   "metadata": {},
   "source": [
    "## 2. Define Sigmoid Activation Function\n",
    "\n",
    "The sigmoid function is defined as: `sigmoid(z) = 1 / (1 + e^(-z))`\n",
    "\n",
    "This function will be used as the activation function for both hidden and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calculate the sigmoid activation function.\n",
    "    \n",
    "    Args:\n",
    "        z (float): Input value to the sigmoid function\n",
    "        \n",
    "    Returns:\n",
    "        float: Output of sigmoid function (1 / (1 + e^-z))\n",
    "    \"\"\"\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "# Test the sigmoid function\n",
    "print(\"Testing sigmoid function:\")\n",
    "test_values = [-2, -1, 0, 1, 2]\n",
    "for val in test_values:\n",
    "    result = sigmoid(val)\n",
    "    print(f\"sigmoid({val}) = {result:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead154f8",
   "metadata": {},
   "source": [
    "## 3. Generate Random Network Parameters\n",
    "\n",
    "Create functions to generate random inputs, weights, and biases for the neural network layers using `random.uniform(-1, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f25c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_inputs(size):\n",
    "    \"\"\"Generate random input values between -1 and 1.\"\"\"\n",
    "    return [random.uniform(-1, 1) for _ in range(size)]\n",
    "\n",
    "def generate_random_weights(rows, cols):\n",
    "    \"\"\"Generate random weight matrix between -1 and 1.\"\"\"\n",
    "    return [[random.uniform(-1, 1) for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "def generate_random_biases(size):\n",
    "    \"\"\"Generate random bias values between -1 and 1.\"\"\"\n",
    "    return [random.uniform(-1, 1) for _ in range(size)]\n",
    "\n",
    "# Test the random generation functions\n",
    "print(\"Testing random generation functions:\")\n",
    "print(\"Random inputs (3):\", [round(x, 3) for x in generate_random_inputs(3)])\n",
    "print(\"Random weights (2x3):\", [[round(w, 3) for w in row] for row in generate_random_weights(2, 3)])\n",
    "print(\"Random biases (2):\", [round(b, 3) for b in generate_random_biases(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c8408",
   "metadata": {},
   "source": [
    "## 4. Implement Forward Pass for Hidden Layer\n",
    "\n",
    "Implement the forward propagation through the hidden layer with 2 neurons. Each neuron:\n",
    "1. Calculates weighted sum: `z = x1*w1 + x2*w2 + x3*w3 + bias`\n",
    "2. Applies sigmoid activation: `output = sigmoid(z)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1309e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_hidden_layer(inputs, weights, biases):\n",
    "    \"\"\"\n",
    "    Perform forward pass through hidden layer.\n",
    "    \n",
    "    Args:\n",
    "        inputs (list): Input values [x1, x2, x3]\n",
    "        weights (list): Weight matrix [[w11, w12, w13], [w21, w22, w23]]\n",
    "        biases (list): Bias values [b1, b2]\n",
    "        \n",
    "    Returns:\n",
    "        list: Output values from hidden layer after sigmoid activation\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for i, neuron_weights in enumerate(weights):\n",
    "        # Calculate weighted sum for each neuron\n",
    "        z = sum(x * w for x, w in zip(inputs, neuron_weights)) + biases[i]\n",
    "        # Apply sigmoid activation\n",
    "        output = sigmoid(z)\n",
    "        outputs.append(output)\n",
    "        \n",
    "        # Print detailed calculation\n",
    "        print(f\"Hidden Neuron {i+1}:\")\n",
    "        print(f\"  z = {' + '.join([f'{x:.3f}*{w:.3f}' for x, w in zip(inputs, neuron_weights)])} + {biases[i]:.3f}\")\n",
    "        print(f\"  z = {z:.3f}\")\n",
    "        print(f\"  output = sigmoid({z:.3f}) = {output:.3f}\")\n",
    "        print()\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Test hidden layer forward pass\n",
    "print(\"Testing Hidden Layer Forward Pass:\")\n",
    "test_inputs = [0.4, -0.2, 0.6]\n",
    "test_weights = [[0.5, -0.3, 0.2], [-0.6, 0.1, 0.7]]\n",
    "test_biases = [0.1, -0.2]\n",
    "\n",
    "hidden_outputs = forward_pass_hidden_layer(test_inputs, test_weights, test_biases)\n",
    "print(f\"Hidden layer outputs: {[round(h, 3) for h in hidden_outputs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ae473",
   "metadata": {},
   "source": [
    "## 5. Implement Forward Pass for Output Layer\n",
    "\n",
    "Implement the forward propagation through the output layer with 1 neuron. The neuron:\n",
    "1. Takes inputs from hidden layer outputs\n",
    "2. Calculates weighted sum: `z = h1*w1 + h2*w2 + bias`\n",
    "3. Applies sigmoid activation: `final_output = sigmoid(z)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d160ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_output_layer(hidden_outputs, weights, bias):\n",
    "    \"\"\"\n",
    "    Perform forward pass through output layer.\n",
    "    \n",
    "    Args:\n",
    "        hidden_outputs (list): Output values from hidden layer\n",
    "        weights (list): Weight values for output layer\n",
    "        bias (float): Bias value for output layer\n",
    "        \n",
    "    Returns:\n",
    "        float: Final output after sigmoid activation\n",
    "    \"\"\"\n",
    "    # Calculate weighted sum\n",
    "    z = sum(h * w for h, w in zip(hidden_outputs, weights)) + bias\n",
    "    \n",
    "    # Print detailed calculation\n",
    "    print(\"Output Layer:\")\n",
    "    print(f\"  z = {' + '.join([f'{h:.3f}*{w:.3f}' for h, w in zip(hidden_outputs, weights)])} + {bias:.3f}\")\n",
    "    print(f\"  z = {z:.3f}\")\n",
    "    \n",
    "    # Apply sigmoid activation\n",
    "    final_output = sigmoid(z)\n",
    "    print(f\"  final_output = sigmoid({z:.3f}) = {final_output:.3f}\")\n",
    "    \n",
    "    return final_output\n",
    "\n",
    "# Test output layer forward pass\n",
    "print(\"Testing Output Layer Forward Pass:\")\n",
    "test_hidden_outputs = [0.618, 0.49]  # From previous hidden layer test\n",
    "test_output_weights = [0.3, -0.4]\n",
    "test_output_bias = 0.2\n",
    "\n",
    "final_output = forward_pass_output_layer(test_hidden_outputs, test_output_weights, test_output_bias)\n",
    "print(f\"\\nFinal output: {final_output:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cf5a1",
   "metadata": {},
   "source": [
    "## 6. Create Complete Neural Network Function\n",
    "\n",
    "Combine all components to create a complete two-layer neural network that:\n",
    "- Generates random parameters\n",
    "- Shows all values and intermediate outputs\n",
    "- Displays detailed calculations for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_neural_network():\n",
    "    \"\"\"\n",
    "    Complete two-layer neural network with random parameters.\n",
    "    Shows all intermediate values and detailed calculations.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TWO-LAYER NEURAL NETWORK WITH RANDOM INPUTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate 3 random input values\n",
    "    inputs = generate_random_inputs(3)\n",
    "    print(f\"Inputs: {[round(x, 3) for x in inputs]}\")\n",
    "    print()\n",
    "    \n",
    "    # First layer: 2 neurons with 3 inputs each\n",
    "    hidden_weights = generate_random_weights(2, 3)\n",
    "    hidden_biases = generate_random_biases(2)\n",
    "    \n",
    "    print(f\"Hidden layer weights: {[[round(w, 3) for w in neuron] for neuron in hidden_weights]}\")\n",
    "    print(f\"Hidden layer biases: {[round(b, 3) for b in hidden_biases]}\")\n",
    "    print()\n",
    "    \n",
    "    # Forward pass through hidden layer (without detailed printing for clean output)\n",
    "    hidden_outputs = []\n",
    "    for i, neuron_weights in enumerate(hidden_weights):\n",
    "        z = sum(x * w for x, w in zip(inputs, neuron_weights)) + hidden_biases[i]\n",
    "        output = sigmoid(z)\n",
    "        hidden_outputs.append(output)\n",
    "    \n",
    "    print(f\"Hidden outputs: {[round(h, 3) for h in hidden_outputs]}\")\n",
    "    print()\n",
    "    \n",
    "    # Second layer: 1 output neuron with 2 inputs from hidden layer\n",
    "    output_weights = generate_random_weights(1, 2)[0]  # Get first row since it's 1 neuron\n",
    "    output_bias = generate_random_biases(1)[0]  # Get first bias since it's 1 neuron\n",
    "    \n",
    "    print(f\"Output layer weights: {[round(w, 3) for w in output_weights]}\")\n",
    "    print(f\"Output layer bias: {round(output_bias, 3)}\")\n",
    "    print()\n",
    "    \n",
    "    # Forward pass through output layer\n",
    "    z_output = sum(h * w for h, w in zip(hidden_outputs, output_weights)) + output_bias\n",
    "    final_output = sigmoid(z_output)\n",
    "    \n",
    "    print(f\"Final Output: {round(final_output, 3)}\")\n",
    "    print()\n",
    "    \n",
    "    # Show detailed calculations\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DETAILED CALCULATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Hidden layer calculations\n",
    "    print(\"Hidden Layer Calculations:\")\n",
    "    for i, (neuron_weights, bias) in enumerate(zip(hidden_weights, hidden_biases)):\n",
    "        z = sum(x * w for x, w in zip(inputs, neuron_weights)) + bias\n",
    "        output = sigmoid(z)\n",
    "        calculation_str = \" + \".join([f\"({x:.3f}×{w:.3f})\" for x, w in zip(inputs, neuron_weights)])\n",
    "        print(f\"  Neuron {i+1}: z = {calculation_str} + {bias:.3f} = {z:.3f}\")\n",
    "        print(f\"  Neuron {i+1}: output = sigmoid({z:.3f}) = {output:.3f}\")\n",
    "        print()\n",
    "    \n",
    "    # Output layer calculations\n",
    "    print(\"Output Layer Calculations:\")\n",
    "    calculation_str = \" + \".join([f\"({h:.3f}×{w:.3f})\" for h, w in zip(hidden_outputs, output_weights)])\n",
    "    print(f\"  z = {calculation_str} + {output_bias:.3f} = {z_output:.3f}\")\n",
    "    print(f\"  final_output = sigmoid({z_output:.3f}) = {final_output:.3f}\")\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e410fd2",
   "metadata": {},
   "source": [
    "## 7. Demo with Fixed Values\n",
    "\n",
    "Run the neural network with fixed input values and parameters similar to the expected output format to demonstrate consistent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo with fixed values (similar to expected output format)\n",
    "print(\"DEMO WITH FIXED VALUES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fixed values similar to expected output\n",
    "inputs = [0.4, -0.2, 0.6]\n",
    "hidden_weights = [[0.5, -0.3, 0.2], [-0.6, 0.1, 0.7]]\n",
    "hidden_biases = [0.1, -0.2]\n",
    "output_weights = [0.3, -0.4]\n",
    "output_bias = 0.2\n",
    "\n",
    "print(f\"Inputs: {inputs}\")\n",
    "print(f\"Hidden layer weights: {hidden_weights}\")\n",
    "print(f\"Hidden layer biases: {hidden_biases}\")\n",
    "\n",
    "# Calculate hidden layer outputs\n",
    "hidden_outputs = []\n",
    "for i, neuron_weights in enumerate(hidden_weights):\n",
    "    z = sum(x * w for x, w in zip(inputs, neuron_weights)) + hidden_biases[i]\n",
    "    output = sigmoid(z)\n",
    "    hidden_outputs.append(output)\n",
    "\n",
    "print(f\"Hidden outputs: {[round(h, 3) for h in hidden_outputs]}\")\n",
    "print(f\"Output layer weights: {output_weights}\")\n",
    "print(f\"Output layer bias: {output_bias}\")\n",
    "\n",
    "# Calculate final output\n",
    "z_final = sum(h * w for h, w in zip(hidden_outputs, output_weights)) + output_bias\n",
    "final_output = sigmoid(z_final)\n",
    "\n",
    "print(f\"Final Output: {round(final_output, 3)}\")\n",
    "\n",
    "# Show step-by-step calculations\n",
    "print(\"\\nStep-by-step calculations:\")\n",
    "print(\"Hidden Layer:\")\n",
    "for i, (neuron_weights, bias) in enumerate(zip(hidden_weights, hidden_biases)):\n",
    "    z = sum(x * w for x, w in zip(inputs, neuron_weights)) + bias\n",
    "    output = sigmoid(z)\n",
    "    print(f\"  Neuron {i+1}: z = {inputs[0]}×{neuron_weights[0]} + {inputs[1]}×{neuron_weights[1]} + {inputs[2]}×{neuron_weights[2]} + {bias} = {z}\")\n",
    "    print(f\"  Neuron {i+1}: sigmoid({z}) = {output:.3f}\")\n",
    "\n",
    "print(\"Output Layer:\")\n",
    "print(f\"  z = {hidden_outputs[0]:.3f}×{output_weights[0]} + {hidden_outputs[1]:.3f}×{output_weights[1]} + {output_bias} = {z_final:.3f}\")\n",
    "print(f\"  final_output = sigmoid({z_final:.3f}) = {final_output:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeea388",
   "metadata": {},
   "source": [
    "## 8. Run Neural Network with Random Parameters\n",
    "\n",
    "Execute the neural network with randomly generated parameters and display both the results and detailed step-by-step calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00365149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete neural network with random parameters\n",
    "result = two_layer_neural_network()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL RESULT: {result:.3f}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nNote: Run this cell multiple times to see different random values!\")\n",
    "print(\"Each execution will generate new random inputs, weights, and biases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733a38e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully implements a **two-layer neural network** with the following specifications:\n",
    "\n",
    "### Network Architecture:\n",
    "- **Input Layer**: 3 random input values (x1, x2, x3)\n",
    "- **Hidden Layer**: 2 neurons with random weights and biases\n",
    "- **Output Layer**: 1 neuron with random weights and bias\n",
    "- **Activation Function**: Sigmoid function used at each layer\n",
    "\n",
    "### Key Features:\n",
    "✅ Random parameter generation using `random.uniform(-1, 1)`  \n",
    "✅ Forward propagation through both layers  \n",
    "✅ Detailed step-by-step calculations  \n",
    "✅ Clear display of all intermediate values  \n",
    "✅ Both fixed and random value demonstrations  \n",
    "\n",
    "### Mathematical Operations:\n",
    "1. **Hidden Layer**: `z = x1*w1 + x2*w2 + x3*w3 + bias` → `output = sigmoid(z)`\n",
    "2. **Output Layer**: `z = h1*w1 + h2*w2 + bias` → `final_output = sigmoid(z)`\n",
    "\n",
    "The implementation shows how neural networks process information through layers using weighted sums and activation functions to produce the final output."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
