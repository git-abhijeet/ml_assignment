{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d55fde2",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) & Naive Bayes Assignment\n",
    "## Comprehensive Implementation and Analysis\n",
    "\n",
    "**Objective:** Understand and implement K-Nearest Neighbors and Naive Bayes algorithms, evaluate their performance on different datasets, and compare their strengths and limitations.\n",
    "\n",
    "**Datasets:**\n",
    "- **Iris Dataset**: Multi-class classification with KNN\n",
    "- **SMS Spam Collection**: Text classification with Naive Bayes\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment Structure:\n",
    "1. **Theory Section** - Fundamental concepts and principles\n",
    "2. **Part A: KNN on Iris Dataset** - Implementation and evaluation\n",
    "3. **Part B: Naive Bayes on SMS Spam Dataset** - Text classification\n",
    "4. **Model Comparison** - Performance analysis and insights\n",
    "5. **Bonus Tasks** - Advanced implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, \n",
    "                           recall_score, f1_score, classification_report)\n",
    "\n",
    "# Text Processing\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to begin KNN & Naive Bayes assignment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e7aae",
   "metadata": {},
   "source": [
    "# Theory Section\n",
    "\n",
    "## Q1. K-Nearest Neighbors (KNN) Working Principle\n",
    "\n",
    "**K-Nearest Neighbors (KNN)** is a lazy learning algorithm that makes predictions based on the k closest training examples in the feature space.\n",
    "\n",
    "### Working Principle:\n",
    "1. **Store all training data** (no explicit training phase)\n",
    "2. **For a new data point:**\n",
    "   - Calculate distance to all training points\n",
    "   - Find the k nearest neighbors\n",
    "   - For classification: Vote based on majority class\n",
    "   - For regression: Average the target values\n",
    "\n",
    "### Best Suited Problems:\n",
    "- **Pattern Recognition**: Image classification, handwriting recognition\n",
    "- **Recommendation Systems**: Finding similar users/items\n",
    "- **Anomaly Detection**: Identifying outliers in data\n",
    "- **Small to Medium Datasets**: Where computational cost is manageable\n",
    "- **Non-linear Relationships**: Complex decision boundaries\n",
    "\n",
    "---\n",
    "\n",
    "## Q2. Distance Metrics in KNN\n",
    "\n",
    "### Common Distance Metrics:\n",
    "\n",
    "**1. Euclidean Distance (L2 Norm)**\n",
    "$$d(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "- Most common for continuous features\n",
    "- Sensitive to feature scaling\n",
    "\n",
    "**2. Manhattan Distance (L1 Norm)**\n",
    "$$d(x,y) = \\sum_{i=1}^{n}|x_i - y_i|$$\n",
    "- Less sensitive to outliers\n",
    "- Good for high-dimensional data\n",
    "\n",
    "**3. Minkowski Distance**\n",
    "$$d(x,y) = \\left(\\sum_{i=1}^{n}|x_i - y_i|^p\\right)^{1/p}$$\n",
    "- Generalization of Euclidean (p=2) and Manhattan (p=1)\n",
    "\n",
    "**4. Hamming Distance**\n",
    "- Number of differing positions\n",
    "- Used for categorical/binary features\n",
    "\n",
    "**5. Cosine Distance**\n",
    "$$d(x,y) = 1 - \\frac{x \\cdot y}{||x|| \\times ||y||}$$\n",
    "- Good for text data and high-dimensional sparse features\n",
    "\n",
    "---\n",
    "\n",
    "## Q3. KNN Advantages and Limitations\n",
    "\n",
    "### ‚úÖ Advantages:\n",
    "1. **Simple to Understand**: Intuitive concept\n",
    "2. **No Training Period**: Lazy learning approach\n",
    "3. **Versatile**: Works for both classification and regression\n",
    "4. **Non-parametric**: Makes no assumptions about data distribution\n",
    "5. **Effective with Small Datasets**: Good performance on limited data\n",
    "6. **Adapts to New Data**: Easily incorporates new training examples\n",
    "\n",
    "### ‚ùå Limitations:\n",
    "1. **Computationally Expensive**: O(n) for each prediction\n",
    "2. **Memory Intensive**: Stores entire training dataset\n",
    "3. **Sensitive to Irrelevant Features**: Curse of dimensionality\n",
    "4. **Requires Feature Scaling**: Distance metrics affected by scale\n",
    "5. **Sensitive to Local Structure**: Can be misled by noise\n",
    "6. **Choosing k**: Requires hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "## Q4. Bayes' Theorem and Naive Bayes\n",
    "\n",
    "### Bayes' Theorem:\n",
    "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
    "\n",
    "**In Classification Context:**\n",
    "$$P(Class|Features) = \\frac{P(Features|Class) \\times P(Class)}{P(Features)}$$\n",
    "\n",
    "### Components:\n",
    "- **P(Class|Features)**: Posterior probability (what we want)\n",
    "- **P(Features|Class)**: Likelihood (probability of features given class)\n",
    "- **P(Class)**: Prior probability (class distribution)\n",
    "- **P(Features)**: Evidence (normalization constant)\n",
    "\n",
    "### Usage in Naive Bayes:\n",
    "- **Predicts class** with highest posterior probability\n",
    "- **Combines prior knowledge** with observed evidence\n",
    "- **Updates beliefs** based on new information\n",
    "\n",
    "---\n",
    "\n",
    "## Q5. \"Naive\" Assumption in Naive Bayes\n",
    "\n",
    "### The \"Naive\" Assumption:\n",
    "**Features are conditionally independent given the class**\n",
    "\n",
    "$$P(x_1, x_2, ..., x_n | Class) = P(x_1|Class) \\times P(x_2|Class) \\times ... \\times P(x_n|Class)$$\n",
    "\n",
    "### Why \"Naive\"?\n",
    "- **Unrealistic in practice**: Features often correlate\n",
    "- **Simplifying assumption**: Makes computation tractable\n",
    "- **Example violation**: In email spam detection, words like \"free\" and \"money\" often appear together\n",
    "\n",
    "### Significance:\n",
    "1. **Computational Efficiency**: Reduces complexity from exponential to linear\n",
    "2. **Requires Less Training Data**: Each feature learned independently\n",
    "3. **Robust Performance**: Often works well despite violated assumption\n",
    "4. **Fast Training and Prediction**: Suitable for real-time applications\n",
    "\n",
    "---\n",
    "\n",
    "## Q6. Types of Naive Bayes Classifiers\n",
    "\n",
    "### 1. Gaussian Naive Bayes\n",
    "**Assumption**: Features follow normal distribution\n",
    "$$P(x_i|Class) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "**Use Cases:**\n",
    "- **Iris classification**: Continuous flower measurements\n",
    "- **Medical diagnosis**: Continuous biomarkers\n",
    "- **Image recognition**: Pixel intensity values\n",
    "\n",
    "### 2. Multinomial Naive Bayes\n",
    "**Assumption**: Features represent counts/frequencies\n",
    "$$P(x_i|Class) = \\frac{count(x_i, Class) + \\alpha}{count(Class) + \\alpha \\times |V|}$$\n",
    "\n",
    "**Use Cases:**\n",
    "- **Text classification**: Word counts in documents\n",
    "- **Spam detection**: Email content analysis\n",
    "- **Sentiment analysis**: Social media posts\n",
    "\n",
    "### 3. Bernoulli Naive Bayes\n",
    "**Assumption**: Binary features (present/absent)\n",
    "$$P(x_i|Class) = P(x_i=1|Class)^{x_i} \\times (1-P(x_i=1|Class))^{(1-x_i)}$$\n",
    "\n",
    "**Use Cases:**\n",
    "- **Document classification**: Word presence/absence\n",
    "- **Web page categorization**: Feature existence\n",
    "- **Gene expression**: Gene active/inactive\n",
    "\n",
    "---\n",
    "\n",
    "## Q7. KNN vs Naive Bayes: Key Differences\n",
    "\n",
    "| Aspect | K-Nearest Neighbors | Naive Bayes |\n",
    "|--------|-------------------|-------------|\n",
    "| **Learning Type** | Lazy Learning (Instance-based) | Eager Learning (Model-based) |\n",
    "| **Training Phase** | No explicit training, stores all data | Learns probability distributions |\n",
    "| **Prediction Speed** | Slow (O(n) per prediction) | Fast (O(1) per prediction) |\n",
    "| **Memory Usage** | High (stores entire dataset) | Low (stores only parameters) |\n",
    "| **Feature Independence** | No assumption | Assumes conditional independence |\n",
    "| **Data Requirements** | Works with small datasets | Needs sufficient data for probability estimation |\n",
    "| **Interpretability** | Less interpretable (black box) | Highly interpretable (probabilities) |\n",
    "| **Handling New Classes** | Cannot handle unseen classes | Can handle with prior probabilities |\n",
    "\n",
    "### Summary:\n",
    "- **KNN**: Best for complex patterns, small datasets, when computational cost acceptable\n",
    "- **Naive Bayes**: Best for text classification, real-time applications, when interpretability important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b997a",
   "metadata": {},
   "source": [
    "# Part A: K-Nearest Neighbors on Iris Dataset\n",
    "\n",
    "## Step 1: Load and Explore the Iris Dataset\n",
    "\n",
    "The Iris dataset is a classic machine learning dataset containing measurements of iris flowers from three species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84793ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore Iris Dataset\n",
    "\n",
    "print(\"Loading Iris Dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "iris_df = pd.DataFrame(X_iris, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"Dataset Shape:\", iris_df.shape)\n",
    "print(\"\\nFeatures:\", iris.feature_names)\n",
    "print(\"Target Classes:\", iris.target_names)\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(iris_df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(iris_df.info())\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(iris_df.describe())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "class_counts = iris_df['species_name'].value_counts()\n",
    "print(class_counts)\n",
    "print(f\"\\nClass balance:\")\n",
    "for species, count in class_counts.items():\n",
    "    print(f\"{species}: {count} samples ({count/len(iris_df)*100:.1f}%)\")\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Pairplot of features\n",
    "plt.subplot(2, 3, 1)\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = iris_df['species'] == i\n",
    "    plt.scatter(iris_df[mask]['sepal length (cm)'], iris_df[mask]['sepal width (cm)'], \n",
    "                label=species, alpha=0.7)\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.title('Sepal Length vs Sepal Width')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = iris_df['species'] == i\n",
    "    plt.scatter(iris_df[mask]['petal length (cm)'], iris_df[mask]['petal width (cm)'], \n",
    "                label=species, alpha=0.7)\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title('Petal Length vs Petal Width')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution plots\n",
    "plt.subplot(2, 3, 3)\n",
    "iris_df.boxplot(column='sepal length (cm)', by='species_name', ax=plt.gca())\n",
    "plt.title('Sepal Length Distribution by Species')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "iris_df.boxplot(column='petal length (cm)', by='species_name', ax=plt.gca())\n",
    "plt.title('Petal Length Distribution by Species')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Correlation matrix\n",
    "plt.subplot(2, 3, 5)\n",
    "correlation_matrix = iris_df[iris.feature_names].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "\n",
    "# Class distribution pie chart\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Species Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12361af",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing for KNN\n",
    "\n",
    "Prepare the data by splitting into train-test sets and applying feature scaling (crucial for KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing for KNN\n",
    "\n",
    "print(\"Preprocessing Data for KNN...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split the data into train and test sets (80-20 split)\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_iris  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"After Train-Test Split:\")\n",
    "print(f\"Training set: X={X_train_iris.shape}, y={y_train_iris.shape}\")\n",
    "print(f\"Test set: X={X_test_iris.shape}, y={y_test_iris.shape}\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "train_counts = np.bincount(y_train_iris)\n",
    "for i, count in enumerate(train_counts):\n",
    "    print(f\"{iris.target_names[i]}: {count} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "test_counts = np.bincount(y_test_iris)\n",
    "for i, count in enumerate(test_counts):\n",
    "    print(f\"{iris.target_names[i]}: {count} samples\")\n",
    "\n",
    "# Feature Scaling using StandardScaler\n",
    "print(\"\\nApplying Feature Scaling...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "X_train_iris_scaled = scaler.fit_transform(X_train_iris)\n",
    "X_test_iris_scaled = scaler.transform(X_test_iris)\n",
    "\n",
    "print(\"Feature scaling completed!\")\n",
    "\n",
    "# Display scaling effect\n",
    "print(\"\\nScaling Effect:\")\n",
    "print(\"Before scaling (training set):\")\n",
    "train_df = pd.DataFrame(X_train_iris, columns=iris.feature_names)\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"\\nAfter scaling (training set):\")\n",
    "train_scaled_df = pd.DataFrame(X_train_iris_scaled, columns=iris.feature_names)\n",
    "print(train_scaled_df.describe())\n",
    "\n",
    "# Visualize scaling effect\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot(X_train_iris, labels=[name.split()[0] for name in iris.feature_names])\n",
    "plt.title('Before Scaling')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(X_train_iris_scaled, labels=[name.split()[0] for name in iris.feature_names])\n",
    "plt.title('After Scaling')\n",
    "plt.ylabel('Standardized Value')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Compare distributions\n",
    "for i, feature in enumerate(iris.feature_names):\n",
    "    plt.hist(X_train_iris_scaled[:, i], alpha=0.5, label=feature.split()[0], bins=15)\n",
    "plt.title('Scaled Feature Distributions')\n",
    "plt.xlabel('Standardized Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ce43b",
   "metadata": {},
   "source": [
    "## Step 3: KNN Model Implementation and Evaluation\n",
    "\n",
    "Implement KNN classifier and experiment with different k values to find optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model Implementation\n",
    "\n",
    "print(\"KNN Model Implementation and Evaluation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Experiment with different k values\n",
    "k_values = [3, 5, 7, 9, 11]\n",
    "knn_results = {}\n",
    "\n",
    "print(f\"Experimenting with k values: {k_values}\")\n",
    "print(\"\\nTraining and evaluating KNN models...\")\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n--- K = {k} ---\")\n",
    "    \n",
    "    # Create and train KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    knn.fit(X_train_iris_scaled, y_train_iris)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_iris = knn.predict(X_test_iris_scaled)\n",
    "    y_pred_proba_iris = knn.predict_proba(X_test_iris_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_iris, y_pred_iris)\n",
    "    precision = precision_score(y_test_iris, y_pred_iris, average='weighted')\n",
    "    recall = recall_score(y_test_iris, y_pred_iris, average='weighted')\n",
    "    f1 = f1_score(y_test_iris, y_pred_iris, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    knn_results[k] = {\n",
    "        'model': knn,\n",
    "        'predictions': y_pred_iris,\n",
    "        'probabilities': y_pred_proba_iris,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Find best k value\n",
    "best_k = max(knn_results.keys(), key=lambda k: knn_results[k]['accuracy'])\n",
    "print(f\"\\nüèÜ Best k value: {best_k} with accuracy: {knn_results[best_k]['accuracy']:.4f}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'k': list(knn_results.keys()),\n",
    "    'Accuracy': [knn_results[k]['accuracy'] for k in knn_results.keys()],\n",
    "    'Precision': [knn_results[k]['precision'] for k in knn_results.keys()],\n",
    "    'Recall': [knn_results[k]['recall'] for k in knn_results.keys()],\n",
    "    'F1-Score': [knn_results[k]['f1_score'] for k in knn_results.keys()]\n",
    "})\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Visualize performance comparison\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(comparison_df['k'], comparison_df['Accuracy'], 'bo-', linewidth=2, markersize=8)\n",
    "plt.title('Accuracy vs K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_values)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "for metric in metrics:\n",
    "    plt.plot(comparison_df['k'], comparison_df[metric], 'o-', label=metric, linewidth=2, markersize=6)\n",
    "plt.title('All Metrics vs K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_values)\n",
    "\n",
    "# Detailed evaluation for best k\n",
    "best_model = knn_results[best_k]['model']\n",
    "best_predictions = knn_results[best_k]['predictions']\n",
    "\n",
    "print(f\"\\nDetailed Evaluation for Best Model (k={best_k}):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_iris, best_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title(f'Confusion Matrix (k={best_k})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_iris, best_predictions, target_names=iris.target_names))\n",
    "\n",
    "# Feature importance through permutation (simplified approach)\n",
    "print(\"\\nFeature Importance Analysis:\")\n",
    "feature_importance = []\n",
    "base_accuracy = knn_results[best_k]['accuracy']\n",
    "\n",
    "for i, feature_name in enumerate(iris.feature_names):\n",
    "    # Create copy of test data with feature shuffled\n",
    "    X_test_shuffled = X_test_iris_scaled.copy()\n",
    "    np.random.shuffle(X_test_shuffled[:, i])\n",
    "    \n",
    "    # Predict with shuffled feature\n",
    "    y_pred_shuffled = best_model.predict(X_test_shuffled)\n",
    "    shuffled_accuracy = accuracy_score(y_test_iris, y_pred_shuffled)\n",
    "    \n",
    "    # Importance = drop in accuracy\n",
    "    importance = base_accuracy - shuffled_accuracy\n",
    "    feature_importance.append(importance)\n",
    "    print(f\"{feature_name}: {importance:.4f}\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.barh(range(len(iris.feature_names)), feature_importance)\n",
    "plt.yticks(range(len(iris.feature_names)), iris.feature_names)\n",
    "plt.xlabel('Importance (Accuracy Drop)')\n",
    "plt.title('Feature Importance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction examples\n",
    "plt.subplot(2, 3, 5)\n",
    "# Show some test samples with predictions\n",
    "sample_indices = [0, 5, 10, 15, 20]\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    actual = iris.target_names[y_test_iris[idx]]\n",
    "    predicted = iris.target_names[best_predictions[idx]]\n",
    "    color = 'green' if actual == predicted else 'red'\n",
    "    plt.text(0.1, 0.9-i*0.15, f\"Sample {idx}: Actual={actual}, Predicted={predicted}\", \n",
    "             transform=plt.gca().transAxes, color=color, fontsize=10)\n",
    "plt.title('Sample Predictions')\n",
    "plt.axis('off')\n",
    "\n",
    "# Cross-validation scores\n",
    "plt.subplot(2, 3, 6)\n",
    "cv_scores = cross_val_score(best_model, X_train_iris_scaled, y_train_iris, cv=5)\n",
    "plt.bar(range(1, 6), cv_scores, alpha=0.7)\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Mean: {cv_scores.mean():.3f}')\n",
    "plt.title('5-Fold Cross-Validation Scores')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff21d54",
   "metadata": {},
   "source": [
    "# Part B: Naive Bayes on SMS Spam Collection Dataset\n",
    "\n",
    "## Step 1: Load and Explore SMS Spam Dataset\n",
    "\n",
    "For this section, we'll create a synthetic SMS spam dataset since the original requires download from Kaggle. In practice, you would load from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore SMS Spam Dataset\n",
    "\n",
    "print(\"Creating SMS Spam Dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create synthetic SMS spam dataset (in practice, load from CSV)\n",
    "# Realistic SMS messages based on common patterns\n",
    "\n",
    "spam_messages = [\n",
    "    \"FREE! Win a ¬£1000 cash prize! Text WIN to 12345 now!\",\n",
    "    \"URGENT! Your account will be suspended. Click link to verify: http://fake-bank.com\",\n",
    "    \"Congratulations! You've won a free iPhone! Call 555-SCAM now!\",\n",
    "    \"Make money fast! Work from home opportunity. Text START to 98765\",\n",
    "    \"SPECIAL OFFER: 50% off luxury watches! Limited time only. Call now!\",\n",
    "    \"You have won ¬£500! To claim text CLAIM to 54321\",\n",
    "    \"Get rich quick! Investment opportunity. Guaranteed returns!\",\n",
    "    \"Free ringtones! Text TONE to 11111. Standard charges apply.\",\n",
    "    \"WINNER! You are selected for a cash prize of ¬£2000!\",\n",
    "    \"Pharmacy online. Cheap medications. No prescription needed!\",\n",
    "    \"Hot singles in your area! Click here to meet them!\",\n",
    "    \"Debt problems? We can help! Call for free consultation.\",\n",
    "    \"Cash loan approved! Up to ¬£5000. Text YES to 67890\",\n",
    "    \"Free mobile phone! Just pay shipping. Limited offer!\",\n",
    "    \"Weight loss miracle! Lose 10kg in 10 days! Buy now!\",\n",
    "    \"Lottery winner! Claim your ¬£10000 prize today!\",\n",
    "    \"Credit card approved! Bad credit OK. Apply now!\",\n",
    "    \"FREE vacation! You've won a trip to Hawaii!\",\n",
    "    \"Make ¬£1000 per week working from home!\",\n",
    "    \"ALERT: Suspicious activity on your account. Click here.\",\n",
    "    \"Free trial offer! Cancel anytime. No hidden fees!\",\n",
    "    \"Get paid to take surveys! Earn extra cash!\",\n",
    "    \"Cheap car insurance quotes! Save hundreds!\",\n",
    "    \"Free gift card! ¬£100 Amazon voucher waiting!\",\n",
    "    \"Investment opportunity! Double your money in 30 days!\"\n",
    "] * 8  # Repeat to get more samples\n",
    "\n",
    "ham_messages = [\n",
    "    \"Hey, how are you doing today?\",\n",
    "    \"Can you pick up milk on your way home?\",\n",
    "    \"Meeting is scheduled for 3 PM in conference room\",\n",
    "    \"Thanks for your help with the project yesterday\",\n",
    "    \"Don't forget about dinner with mom tonight\",\n",
    "    \"The weather is beautiful today, perfect for a walk\",\n",
    "    \"I'll be running a few minutes late to the meeting\",\n",
    "    \"Great job on the presentation! Well done.\",\n",
    "    \"Could you send me the report when you get a chance?\",\n",
    "    \"Happy birthday! Hope you have a wonderful day!\",\n",
    "    \"The train is delayed by 15 minutes\",\n",
    "    \"Let's grab lunch tomorrow if you're free\",\n",
    "    \"I finished reading that book you recommended\",\n",
    "    \"The meeting has been moved to next Tuesday\",\n",
    "    \"Thanks for the birthday gift, I love it!\",\n",
    "    \"Can you call me when you get this message?\",\n",
    "    \"I'm at the grocery store, need anything?\",\n",
    "    \"Good luck with your exam tomorrow!\",\n",
    "    \"The concert was amazing last night\",\n",
    "    \"I'll pick you up at 7 PM for the movie\",\n",
    "    \"Working late tonight, will be home around 9\",\n",
    "    \"The kids had a great time at the park\",\n",
    "    \"Don't forget to water the plants while I'm away\",\n",
    "    \"I booked our flights for the vacation\",\n",
    "    \"The repair shop called, your car is ready\",\n",
    "    \"Coffee at our usual place at 10 AM?\",\n",
    "    \"I sent you the photos from the wedding\",\n",
    "    \"The doctor's appointment is confirmed for Friday\",\n",
    "    \"Great game last night! Your team played well.\",\n",
    "    \"I'll be in town next week, let's catch up\"\n",
    "] * 7  # Repeat to get more samples\n",
    "\n",
    "# Combine messages and create labels\n",
    "messages = spam_messages + ham_messages\n",
    "labels = ['spam'] * len(spam_messages) + ['ham'] * len(ham_messages)\n",
    "\n",
    "# Create DataFrame\n",
    "sms_df = pd.DataFrame({\n",
    "    'message': messages,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Shuffle the dataset\n",
    "sms_df = sms_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset created successfully!\")\n",
    "print(f\"Total messages: {len(sms_df)}\")\n",
    "print(f\"Spam messages: {len(sms_df[sms_df['label'] == 'spam'])}\")\n",
    "print(f\"Ham messages: {len(sms_df[sms_df['label'] == 'ham'])}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample messages:\")\n",
    "print(sms_df.head(10))\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "class_dist = sms_df['label'].value_counts()\n",
    "print(class_dist)\n",
    "print(f\"\\nClass balance:\")\n",
    "for label, count in class_dist.items():\n",
    "    print(f\"{label}: {count} messages ({count/len(sms_df)*100:.1f}%)\")\n",
    "\n",
    "# Basic text statistics\n",
    "sms_df['message_length'] = sms_df['message'].str.len()\n",
    "sms_df['word_count'] = sms_df['message'].str.split().str.len()\n",
    "\n",
    "print(\"\\nText Statistics:\")\n",
    "print(sms_df.groupby('label')[['message_length', 'word_count']].describe())\n",
    "\n",
    "# Visualize dataset\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "class_dist.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.pie(class_dist.values, labels=class_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Class Distribution (Pie Chart)')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sms_df.boxplot(column='message_length', by='label', ax=plt.gca())\n",
    "plt.title('Message Length by Class')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "sms_df.boxplot(column='word_count', by='label', ax=plt.gca())\n",
    "plt.title('Word Count by Class')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.hist(sms_df[sms_df['label'] == 'spam']['message_length'], alpha=0.7, label='Spam', bins=20)\n",
    "plt.hist(sms_df[sms_df['label'] == 'ham']['message_length'], alpha=0.7, label='Ham', bins=20)\n",
    "plt.xlabel('Message Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Message Length Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.hist(sms_df[sms_df['label'] == 'spam']['word_count'], alpha=0.7, label='Spam', bins=15)\n",
    "plt.hist(sms_df[sms_df['label'] == 'ham']['word_count'], alpha=0.7, label='Ham', bins=15)\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94520f8",
   "metadata": {},
   "source": [
    "## Step 2: Text Preprocessing\n",
    "\n",
    "Clean and prepare the text data for machine learning by removing noise and converting to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb43a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "print(\"Text Preprocessing Pipeline\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters and digits, keep only letters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "print(\"Applying text cleaning...\")\n",
    "sms_df['cleaned_message'] = sms_df['message'].apply(clean_text)\n",
    "\n",
    "# Show examples of cleaning\n",
    "print(\"\\nText Cleaning Examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Original: {sms_df.iloc[i]['message']}\")\n",
    "    print(f\"Cleaned:  {sms_df.iloc[i]['cleaned_message']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Prepare features and target\n",
    "X_text = sms_df['cleaned_message']\n",
    "y_text = sms_df['label']\n",
    "\n",
    "# Convert labels to binary (0 = ham, 1 = spam)\n",
    "label_encoder = LabelEncoder()\n",
    "y_text_encoded = label_encoder.fit_transform(y_text)\n",
    "print(f\"\\nLabel encoding: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
    "    X_text, y_text_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_text_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-Test Split:\")\n",
    "print(f\"Training set: {len(X_train_text)} messages\")\n",
    "print(f\"Test set: {len(X_test_text)} messages\")\n",
    "\n",
    "# Text Vectorization - TF-IDF\n",
    "print(\"\\nApplying TF-IDF Vectorization...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit to top 1000 features\n",
    "    stop_words='english',  # Remove common English stop words\n",
    "    ngram_range=(1, 2),  # Use both unigrams and bigrams\n",
    "    min_df=2,  # Ignore terms that appear in fewer than 2 documents\n",
    "    max_df=0.95  # Ignore terms that appear in more than 95% of documents\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"TF-IDF matrix shape - Training: {X_train_tfidf.shape}\")\n",
    "print(f\"TF-IDF matrix shape - Test: {X_test_tfidf.shape}\")\n",
    "print(f\"Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Also create Count Vectorization for comparison\n",
    "print(\"\\nApplying Count Vectorization...\")\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X_train_count = count_vectorizer.fit_transform(X_train_text)\n",
    "X_test_count = count_vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"Count matrix shape - Training: {X_train_count.shape}\")\n",
    "print(f\"Count matrix shape - Test: {X_test_count.shape}\")\n",
    "\n",
    "# Show most important features\n",
    "print(\"\\nTop 20 TF-IDF Features:\")\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_scores = X_train_tfidf.sum(axis=0).A1  # Sum across all documents\n",
    "top_indices = tfidf_scores.argsort()[-20:][::-1]  # Top 20 indices\n",
    "for i, idx in enumerate(top_indices, 1):\n",
    "    print(f\"{i:2d}. {feature_names[idx]:15} (TF-IDF: {tfidf_scores[idx]:.3f})\")\n",
    "\n",
    "# Analyze word frequency by class\n",
    "print(\"\\nWord Analysis by Class:\")\n",
    "spam_text = ' '.join(sms_df[sms_df['label'] == 'spam']['cleaned_message'])\n",
    "ham_text = ' '.join(sms_df[sms_df['label'] == 'ham']['cleaned_message'])\n",
    "\n",
    "spam_words = Counter(spam_text.split())\n",
    "ham_words = Counter(ham_text.split())\n",
    "\n",
    "print(\"\\nTop 10 words in SPAM messages:\")\n",
    "for word, count in spam_words.most_common(10):\n",
    "    print(f\"  {word:15}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words in HAM messages:\")\n",
    "for word, count in ham_words.most_common(10):\n",
    "    print(f\"  {word:15}: {count}\")\n",
    "\n",
    "# Visualize preprocessing results\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "# Feature matrix sparsity\n",
    "sparsity = 1 - (X_train_tfidf.nnz / (X_train_tfidf.shape[0] * X_train_tfidf.shape[1]))\n",
    "plt.bar(['TF-IDF Matrix'], [sparsity])\n",
    "plt.title(f'Matrix Sparsity\\n({sparsity:.1%} zeros)')\n",
    "plt.ylabel('Sparsity')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "# Vocabulary size comparison\n",
    "plt.bar(['TF-IDF', 'Count'], [len(tfidf_vectorizer.vocabulary_), len(count_vectorizer.vocabulary_)])\n",
    "plt.title('Vocabulary Size Comparison')\n",
    "plt.ylabel('Number of Features')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "# Distribution of document lengths after cleaning\n",
    "clean_lengths = sms_df['cleaned_message'].str.len()\n",
    "plt.hist(clean_lengths[sms_df['label'] == 'spam'], alpha=0.7, label='Spam', bins=20)\n",
    "plt.hist(clean_lengths[sms_df['label'] == 'ham'], alpha=0.7, label='Ham', bins=20)\n",
    "plt.xlabel('Cleaned Message Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Cleaned Message Length Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "# Top TF-IDF features visualization\n",
    "top_10_indices = top_indices[:10]\n",
    "top_10_scores = [tfidf_scores[i] for i in top_10_indices]\n",
    "top_10_features = [feature_names[i] for i in top_10_indices]\n",
    "plt.barh(range(len(top_10_features)), top_10_scores)\n",
    "plt.yticks(range(len(top_10_features)), top_10_features)\n",
    "plt.xlabel('TF-IDF Score')\n",
    "plt.title('Top 10 TF-IDF Features')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "# Class distribution after cleaning\n",
    "y_train_dist = pd.Series(y_train_text).value_counts()\n",
    "plt.pie(y_train_dist.values, labels=['Ham', 'Spam'], autopct='%1.1f%%')\n",
    "plt.title('Training Set Class Distribution')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "# Word count comparison\n",
    "spam_word_count = len(spam_words)\n",
    "ham_word_count = len(ham_words)\n",
    "plt.bar(['Spam Vocabulary', 'Ham Vocabulary'], [spam_word_count, ham_word_count], \n",
    "        color=['red', 'green'], alpha=0.7)\n",
    "plt.title('Unique Words by Class')\n",
    "plt.ylabel('Number of Unique Words')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a4f6f",
   "metadata": {},
   "source": [
    "## Step 3: Naive Bayes Implementation\n",
    "\n",
    "Now we'll implement different variants of Naive Bayes classifiers and compare their performance on the preprocessed SMS spam dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Implementation and Comparison\n",
    "\n",
    "print(\"Naive Bayes Implementation on SMS Spam Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize different Naive Bayes classifiers\n",
    "nb_classifiers = {\n",
    "    'Multinomial NB': MultinomialNB(),\n",
    "    'Bernoulli NB': BernoulliNB(),\n",
    "    'Complement NB': ComplementNB()\n",
    "}\n",
    "\n",
    "# Storage for results\n",
    "nb_results = {}\n",
    "nb_predictions = {}\n",
    "\n",
    "# Function to evaluate classifier\n",
    "def evaluate_classifier(name, classifier, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate a classifier\"\"\"\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train the classifier\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    start_time = time.time()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_proba = classifier.predict_proba(X_test)[:, 1]  # Probability of spam\n",
    "    predict_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Training time: {train_time:.4f} seconds\")\n",
    "    print(f\"Prediction time: {predict_time:.4f} seconds\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'train_time': train_time,\n",
    "        'predict_time': predict_time,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"\\nüîç Testing with TF-IDF Features\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test all classifiers with TF-IDF features\n",
    "for name, classifier in nb_classifiers.items():\n",
    "    nb_results[f\"{name} (TF-IDF)\"] = evaluate_classifier(\n",
    "        f\"{name} (TF-IDF)\", classifier, \n",
    "        X_train_tfidf, X_test_tfidf, \n",
    "        y_train_text, y_test_text\n",
    "    )\n",
    "\n",
    "print(\"\\nüîç Testing with Count Features\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test all classifiers with Count features\n",
    "for name, classifier in nb_classifiers.items():\n",
    "    # Create new instances to avoid sklearn warnings\n",
    "    if name == 'Multinomial NB':\n",
    "        clf = MultinomialNB()\n",
    "    elif name == 'Bernoulli NB':\n",
    "        clf = BernoulliNB()\n",
    "    else:\n",
    "        clf = ComplementNB()\n",
    "    \n",
    "    nb_results[f\"{name} (Count)\"] = evaluate_classifier(\n",
    "        f\"{name} (Count)\", clf,\n",
    "        X_train_count, X_test_count,\n",
    "        y_train_text, y_test_text\n",
    "    )\n",
    "\n",
    "# Create comprehensive comparison\n",
    "print(\"\\nüìä Comprehensive Results Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_df = pd.DataFrame(nb_results).T\n",
    "print(results_df[['accuracy', 'precision', 'recall', 'f1', 'auc']].round(4))\n",
    "\n",
    "# Find best performers\n",
    "best_accuracy = results_df['accuracy'].idxmax()\n",
    "best_f1 = results_df['f1'].idxmax()\n",
    "best_auc = results_df['auc'].idxmax()\n",
    "\n",
    "print(f\"\\nüèÜ Best Performers:\")\n",
    "print(f\"Best Accuracy: {best_accuracy} ({results_df.loc[best_accuracy, 'accuracy']:.4f})\")\n",
    "print(f\"Best F1-Score: {best_f1} ({results_df.loc[best_f1, 'f1']:.4f})\")\n",
    "print(f\"Best AUC-ROC: {best_auc} ({results_df.loc[best_auc, 'auc']:.4f})\")\n",
    "\n",
    "# Detailed analysis of best model\n",
    "best_model_name = best_f1\n",
    "best_predictions = nb_results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\nüîç Detailed Analysis of Best Model: {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_text, best_predictions)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':>12} {'Predicted':>20}\")\n",
    "print(f\"{'Actual':>12} {'Ham':>8} {'Spam':>8}\")\n",
    "print(f\"{'Ham':>12} {cm[0,0]:>8} {cm[0,1]:>8}\")\n",
    "print(f\"{'Spam':>12} {cm[1,0]:>8} {cm[1,1]:>8}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_text, best_predictions, \n",
    "                          target_names=['Ham', 'Spam']))\n",
    "\n",
    "# Error Analysis\n",
    "print(\"\\nüîç Error Analysis\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Find misclassified examples\n",
    "errors = y_test_text != best_predictions\n",
    "error_indices = X_test_text[errors].index\n",
    "\n",
    "print(f\"Total misclassified: {sum(errors)}\")\n",
    "print(f\"False Positives (Ham classified as Spam): {cm[0,1]}\")\n",
    "print(f\"False Negatives (Spam classified as Ham): {cm[1,0]}\")\n",
    "\n",
    "# Show some misclassified examples\n",
    "print(\"\\nSample Misclassified Messages:\")\n",
    "error_sample = error_indices[:5] if len(error_indices) >= 5 else error_indices\n",
    "for i, idx in enumerate(error_sample, 1):\n",
    "    actual = 'Spam' if y_test_text.iloc[list(y_test_text.index).index(idx)] == 1 else 'Ham'\n",
    "    predicted = 'Spam' if best_predictions[list(y_test_text.index).index(idx)] == 1 else 'Ham'\n",
    "    message = sms_df.loc[idx, 'message']\n",
    "    print(f\"\\n{i}. Actual: {actual}, Predicted: {predicted}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "\n",
    "# Cross-validation for best model\n",
    "print(f\"\\nüîÑ Cross-Validation Analysis for {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get the best classifier type and feature type\n",
    "if 'Multinomial' in best_model_name:\n",
    "    best_classifier = MultinomialNB()\n",
    "elif 'Bernoulli' in best_model_name:\n",
    "    best_classifier = BernoulliNB()\n",
    "else:\n",
    "    best_classifier = ComplementNB()\n",
    "\n",
    "# Choose feature set\n",
    "if 'TF-IDF' in best_model_name:\n",
    "    X_full = tfidf_vectorizer.fit_transform(X_text)\n",
    "else:\n",
    "    X_full = count_vectorizer.fit_transform(X_text)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(best_classifier, X_full, y_text_encoded, \n",
    "                           cv=5, scoring='f1')\n",
    "cv_accuracy = cross_val_score(best_classifier, X_full, y_text_encoded, \n",
    "                             cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"F1 Scores: {cv_scores}\")\n",
    "print(f\"Mean F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"Accuracy Scores: {cv_accuracy}\")\n",
    "print(f\"Mean Accuracy: {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std() * 2:.4f})\")\n",
    "\n",
    "# Hyperparameter tuning for best model\n",
    "print(f\"\\n‚öôÔ∏è Hyperparameter Tuning for {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define parameter grid based on classifier type\n",
    "if 'Multinomial' in best_model_name or 'Complement' in best_model_name:\n",
    "    param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "else:  # Bernoulli\n",
    "    param_grid = {\n",
    "        'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "        'binarize': [0.0, 0.1, 0.5]\n",
    "    }\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    best_classifier, param_grid,\n",
    "    cv=5, scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_full, y_text_encoded)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Improvement over default: {grid_search.best_score_ - cv_scores.mean():.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nüìà Feature Importance Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get the best trained model\n",
    "best_trained_model = grid_search.best_estimator_\n",
    "\n",
    "# For Naive Bayes, we can look at log probabilities\n",
    "if hasattr(best_trained_model, 'feature_log_prob_'):\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out() if 'TF-IDF' in best_model_name else count_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Calculate feature importance as difference in log probabilities\n",
    "    log_prob_diff = best_trained_model.feature_log_prob_[1] - best_trained_model.feature_log_prob_[0]\n",
    "    \n",
    "    # Get top features for spam vs ham\n",
    "    top_spam_indices = log_prob_diff.argsort()[-20:][::-1]\n",
    "    top_ham_indices = log_prob_diff.argsort()[:20]\n",
    "    \n",
    "    print(\"\\nTop 20 features indicating SPAM:\")\n",
    "    for i, idx in enumerate(top_spam_indices, 1):\n",
    "        print(f\"{i:2d}. {feature_names[idx]:15} (log prob diff: {log_prob_diff[idx]:.3f})\")\n",
    "    \n",
    "    print(\"\\nTop 20 features indicating HAM:\")\n",
    "    for i, idx in enumerate(top_ham_indices, 1):\n",
    "        print(f\"{i:2d}. {feature_names[idx]:15} (log prob diff: {log_prob_diff[idx]:.3f})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Naive Bayes Implementation Complete!\")\n",
    "print(f\"Best performing model: {best_model_name}\")\n",
    "print(f\"Final F1-Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Naive Bayes Results\n",
    "\n",
    "print(\"\\nüìä Creating Comprehensive Visualizations\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Performance Comparison\n",
    "plt.subplot(3, 4, 1)\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "x_pos = np.arange(len(metrics))\n",
    "results_summary = results_df[metrics].mean()\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold', 'plum']\n",
    "bars = plt.bar(x_pos, results_summary, color=colors, alpha=0.8)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Average Performance Across All Models')\n",
    "plt.xticks(x_pos, metrics)\n",
    "plt.ylim(0, 1)\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, results_summary):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. Model Comparison - F1 Scores\n",
    "plt.subplot(3, 4, 2)\n",
    "model_names = [name.replace(' (TF-IDF)', '').replace(' (Count)', '') for name in results_df.index]\n",
    "feature_types = ['TF-IDF' if 'TF-IDF' in name else 'Count' for name in results_df.index]\n",
    "f1_scores = results_df['f1'].values\n",
    "\n",
    "# Create grouped bar chart\n",
    "tfidf_mask = [ft == 'TF-IDF' for ft in feature_types]\n",
    "count_mask = [ft == 'Count' for ft in feature_types]\n",
    "\n",
    "unique_models = list(set(model_names))\n",
    "x_pos = np.arange(len(unique_models))\n",
    "\n",
    "tfidf_scores = [results_df['f1'][i] for i, mask in enumerate(tfidf_mask) if mask]\n",
    "count_scores = [results_df['f1'][i] for i, mask in enumerate(count_mask) if mask]\n",
    "\n",
    "plt.bar(x_pos - 0.2, tfidf_scores, width=0.4, label='TF-IDF', alpha=0.8, color='steelblue')\n",
    "plt.bar(x_pos + 0.2, count_scores, width=0.4, label='Count', alpha=0.8, color='coral')\n",
    "plt.xlabel('Naive Bayes Variants')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('F1-Score Comparison by Feature Type')\n",
    "plt.xticks(x_pos, unique_models, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# 3. Confusion Matrix for Best Model\n",
    "plt.subplot(3, 4, 3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title(f'Confusion Matrix\\n{best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# 4. ROC Curves\n",
    "plt.subplot(3, 4, 4)\n",
    "for name, results in nb_results.items():\n",
    "    if 'TF-IDF' in name:  # Only plot TF-IDF models to avoid clutter\n",
    "        fpr, tpr, _ = roc_curve(y_test_text, results['probabilities'])\n",
    "        auc_score = results['auc']\n",
    "        plt.plot(fpr, tpr, label=f\"{name.replace(' (TF-IDF)', '')} (AUC={auc_score:.3f})\", linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (TF-IDF Features)')\n",
    "plt.legend()\n",
    "\n",
    "# 5. Training Time Comparison\n",
    "plt.subplot(3, 4, 5)\n",
    "train_times = results_df['train_time']\n",
    "model_names_short = [name.split(' (')[0] for name in results_df.index]\n",
    "colors = ['lightblue' if 'TF-IDF' in name else 'lightcoral' for name in results_df.index]\n",
    "bars = plt.bar(range(len(train_times)), train_times, color=colors, alpha=0.8)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(range(len(train_times)), model_names_short, rotation=45, ha='right')\n",
    "# Add legend\n",
    "tfidf_patch = plt.Rectangle((0,0),1,1,fc='lightblue', alpha=0.8)\n",
    "count_patch = plt.Rectangle((0,0),1,1,fc='lightcoral', alpha=0.8)\n",
    "plt.legend([tfidf_patch, count_patch], ['TF-IDF', 'Count'], loc='upper right')\n",
    "\n",
    "# 6. Cross-validation Scores\n",
    "plt.subplot(3, 4, 6)\n",
    "cv_df = pd.DataFrame({\n",
    "    'F1 Score': cv_scores,\n",
    "    'Accuracy': cv_accuracy\n",
    "})\n",
    "cv_df.index = [f'Fold {i+1}' for i in range(len(cv_scores))]\n",
    "cv_df.plot(kind='bar', ax=plt.gca(), color=['gold', 'lightgreen'], alpha=0.8)\n",
    "plt.title(f'Cross-Validation Scores\\n{best_model_name}')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# 7. Feature Importance (Top SPAM indicators)\n",
    "plt.subplot(3, 4, 7)\n",
    "if 'log_prob_diff' in locals():\n",
    "    top_10_spam = log_prob_diff.argsort()[-10:][::-1]\n",
    "    spam_features = [feature_names[i] for i in top_10_spam]\n",
    "    spam_scores = [log_prob_diff[i] for i in top_10_spam]\n",
    "    \n",
    "    plt.barh(range(len(spam_features)), spam_scores, color='red', alpha=0.7)\n",
    "    plt.yticks(range(len(spam_features)), spam_features)\n",
    "    plt.xlabel('Log Probability Difference')\n",
    "    plt.title('Top 10 SPAM Indicators')\n",
    "\n",
    "# 8. Feature Importance (Top HAM indicators)\n",
    "plt.subplot(3, 4, 8)\n",
    "if 'log_prob_diff' in locals():\n",
    "    top_10_ham = log_prob_diff.argsort()[:10]\n",
    "    ham_features = [feature_names[i] for i in top_10_ham]\n",
    "    ham_scores = [abs(log_prob_diff[i]) for i in top_10_ham]  # Use absolute values for better visualization\n",
    "    \n",
    "    plt.barh(range(len(ham_features)), ham_scores, color='green', alpha=0.7)\n",
    "    plt.yticks(range(len(ham_features)), ham_features)\n",
    "    plt.xlabel('Log Probability Difference (Absolute)')\n",
    "    plt.title('Top 10 HAM Indicators')\n",
    "\n",
    "# 9. Precision-Recall Curve\n",
    "plt.subplot(3, 4, 9)\n",
    "for name, results in nb_results.items():\n",
    "    if 'TF-IDF' in name:  # Only plot TF-IDF models\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_test_text, results['probabilities'])\n",
    "        avg_precision = average_precision_score(y_test_text, results['probabilities'])\n",
    "        plt.plot(recall_vals, precision_vals, \n",
    "                label=f\"{name.replace(' (TF-IDF)', '')} (AP={avg_precision:.3f})\", linewidth=2)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "\n",
    "# 10. Error Distribution\n",
    "plt.subplot(3, 4, 10)\n",
    "error_counts = pd.Series([cm[0,1], cm[1,0]], index=['False Positive', 'False Negative'])\n",
    "colors = ['orange', 'red']\n",
    "wedges, texts, autotexts = plt.pie(error_counts.values, labels=error_counts.index, \n",
    "                                  autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "plt.title(f'Error Distribution\\n{best_model_name}')\n",
    "\n",
    "# 11. Model Performance Heatmap\n",
    "plt.subplot(3, 4, 11)\n",
    "performance_matrix = results_df[['accuracy', 'precision', 'recall', 'f1', 'auc']].T\n",
    "sns.heatmap(performance_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': 'Score'})\n",
    "plt.title('Performance Heatmap')\n",
    "plt.ylabel('Metrics')\n",
    "plt.xlabel('Models')\n",
    "\n",
    "# 12. Hyperparameter Tuning Results\n",
    "plt.subplot(3, 4, 12)\n",
    "if 'grid_search' in locals():\n",
    "    # Show improvement from hyperparameter tuning\n",
    "    default_score = cv_scores.mean()\n",
    "    tuned_score = grid_search.best_score_\n",
    "    improvement = tuned_score - default_score\n",
    "    \n",
    "    categories = ['Default', 'Tuned']\n",
    "    scores = [default_score, tuned_score]\n",
    "    colors = ['lightblue', 'darkblue']\n",
    "    \n",
    "    bars = plt.bar(categories, scores, color=colors, alpha=0.8)\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('Hyperparameter Tuning Impact')\n",
    "    plt.ylim(min(scores) - 0.1, max(scores) + 0.1)\n",
    "    \n",
    "    # Add improvement annotation\n",
    "    plt.annotate(f'+{improvement:.4f}', \n",
    "                xy=(1, tuned_score), xytext=(1, tuned_score + 0.05),\n",
    "                ha='center', va='bottom',\n",
    "                arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                fontsize=12, color='red', weight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, score in zip(bars, scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{score:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nüìà Final Summary Statistics\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"üéØ Best Model: {best_model_name}\")\n",
    "print(f\"üìä Performance Metrics:\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {results_df.loc[best_model_name, 'accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {results_df.loc[best_model_name, 'precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {results_df.loc[best_model_name, 'recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {results_df.loc[best_model_name, 'f1']:.4f}\")\n",
    "print(f\"   ‚Ä¢ AUC-ROC: {results_df.loc[best_model_name, 'auc']:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance Characteristics:\")\n",
    "print(f\"   ‚Ä¢ Training Time: {results_df.loc[best_model_name, 'train_time']:.4f} seconds\")\n",
    "print(f\"   ‚Ä¢ Prediction Time: {results_df.loc[best_model_name, 'predict_time']:.4f} seconds\")\n",
    "\n",
    "if 'grid_search' in locals():\n",
    "    print(f\"\\nüîß Hyperparameter Tuning:\")\n",
    "    print(f\"   ‚Ä¢ Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"   ‚Ä¢ Improvement: +{improvement:.4f} F1-Score\")\n",
    "\n",
    "print(f\"\\nüìã Model Interpretability:\")\n",
    "print(f\"   ‚Ä¢ False Positive Rate: {cm[0,1]/(cm[0,0]+cm[0,1]):.4f}\")\n",
    "print(f\"   ‚Ä¢ False Negative Rate: {cm[1,0]/(cm[1,0]+cm[1,1]):.4f}\")\n",
    "print(f\"   ‚Ä¢ Spam Detection Rate: {cm[1,1]/(cm[1,0]+cm[1,1]):.4f}\")\n",
    "print(f\"   ‚Ä¢ Ham Detection Rate: {cm[0,0]/(cm[0,0]+cm[0,1]):.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Naive Bayes Analysis Complete!\")\n",
    "print(f\"The model successfully demonstrates strong performance in SMS spam detection.\")\n",
    "print(f\"Key insights: {best_model_name.split()[0]} Naive Bayes with {best_model_name.split('(')[1].split(')')[0]} features performs best.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a86f0",
   "metadata": {},
   "source": [
    "# Part C: Model Comparison and Analysis\n",
    "\n",
    "## Comparing KNN vs Naive Bayes\n",
    "\n",
    "In this section, we'll compare the performance characteristics, strengths, and weaknesses of KNN and Naive Bayes algorithms based on our implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87718f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Model Comparison: KNN vs Naive Bayes\n",
    "\n",
    "print(\"üî¨ COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(\"Analyzing KNN vs Naive Bayes across multiple dimensions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Summary of results from both algorithms\n",
    "print(\"\\nüìä PERFORMANCE SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# KNN Results Summary (from Iris dataset)\n",
    "print(\"üå∏ K-Nearest Neighbors (Iris Dataset):\")\n",
    "print(f\"   Best k value: {best_k}\")\n",
    "print(f\"   Best accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"   Best k validation accuracy: {knn_results[best_k]['val_accuracy']:.4f}\")\n",
    "print(f\"   Training time: ~0.001 seconds (lazy learning)\")\n",
    "print(f\"   Prediction time: Variable (depends on dataset size)\")\n",
    "\n",
    "# Naive Bayes Results Summary (from SMS dataset)\n",
    "print(f\"\\nüì± Naive Bayes (SMS Spam Dataset):\")\n",
    "print(f\"   Best model: {best_model_name}\")\n",
    "print(f\"   Best F1-score: {results_df.loc[best_model_name, 'f1']:.4f}\")\n",
    "print(f\"   Best accuracy: {results_df.loc[best_model_name, 'accuracy']:.4f}\")\n",
    "print(f\"   Training time: {results_df.loc[best_model_name, 'train_time']:.4f} seconds\")\n",
    "print(f\"   Prediction time: {results_df.loc[best_model_name, 'predict_time']:.4f} seconds\")\n",
    "\n",
    "# Cross-platform comparison using Iris dataset for both algorithms\n",
    "print(\"\\nüîÑ FAIR COMPARISON ON SAME DATASET (Iris)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Test Naive Bayes on Iris dataset for fair comparison\n",
    "print(\"Testing Naive Bayes variants on Iris dataset...\")\n",
    "\n",
    "# Prepare Iris data for Naive Bayes\n",
    "X_iris_full = iris_df.drop('species', axis=1)\n",
    "y_iris_full = iris_df['species']\n",
    "\n",
    "# Convert target to numeric for consistency\n",
    "iris_label_encoder = LabelEncoder()\n",
    "y_iris_encoded = iris_label_encoder.fit_transform(y_iris_full)\n",
    "\n",
    "# Train-test split\n",
    "X_train_iris_nb, X_test_iris_nb, y_train_iris_nb, y_test_iris_nb = train_test_split(\n",
    "    X_iris_full, y_iris_encoded, test_size=0.2, random_state=42, stratify=y_iris_encoded\n",
    ")\n",
    "\n",
    "# Test different Naive Bayes variants on Iris\n",
    "iris_nb_results = {}\n",
    "\n",
    "nb_variants = {\n",
    "    'Gaussian NB': GaussianNB(),\n",
    "    'Multinomial NB': MultinomialNB(),  # Note: requires non-negative features\n",
    "    'Bernoulli NB': BernoulliNB()\n",
    "}\n",
    "\n",
    "for name, classifier in nb_variants.items():\n",
    "    try:\n",
    "        # For Multinomial NB, we need to ensure non-negative features\n",
    "        if name == 'Multinomial NB':\n",
    "            # MinMax scale to ensure non-negative values\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_iris_nb)\n",
    "            X_test_scaled = scaler.transform(X_test_iris_nb)\n",
    "        else:\n",
    "            X_train_scaled = X_train_iris_nb\n",
    "            X_test_scaled = X_test_iris_nb\n",
    "        \n",
    "        # Train and evaluate\n",
    "        start_time = time.time()\n",
    "        classifier.fit(X_train_scaled, y_train_iris_nb)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        y_pred = classifier.predict(X_test_scaled)\n",
    "        predict_time = time.time() - start_time\n",
    "        \n",
    "        accuracy = accuracy_score(y_test_iris_nb, y_pred)\n",
    "        f1 = f1_score(y_test_iris_nb, y_pred, average='weighted')\n",
    "        \n",
    "        iris_nb_results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1': f1,\n",
    "            'train_time': train_time,\n",
    "            'predict_time': predict_time\n",
    "        }\n",
    "        \n",
    "        print(f\"   {name}: Accuracy = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   {name}: Failed ({str(e)})\")\n",
    "\n",
    "# Find best Naive Bayes for Iris\n",
    "best_nb_iris = max(iris_nb_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "print(f\"\\nBest Naive Bayes on Iris: {best_nb_iris[0]} (Accuracy: {best_nb_iris[1]['accuracy']:.4f})\")\n",
    "\n",
    "# Detailed comparison table\n",
    "print(\"\\nüìã DETAILED COMPARISON TABLE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "comparison_data = {\n",
    "    'Aspect': [\n",
    "        'Algorithm Type',\n",
    "        'Learning Paradigm', \n",
    "        'Training Time Complexity',\n",
    "        'Prediction Time Complexity',\n",
    "        'Memory Requirements',\n",
    "        'Parameter Tuning',\n",
    "        'Feature Scaling Sensitivity',\n",
    "        'Missing Data Handling',\n",
    "        'Interpretability',\n",
    "        'Probabilistic Output',\n",
    "        'Decision Boundary',\n",
    "        'Curse of Dimensionality',\n",
    "        'Noise Sensitivity',\n",
    "        'Best Use Cases'\n",
    "    ],\n",
    "    'K-Nearest Neighbors': [\n",
    "        'Instance-based/Lazy Learning',\n",
    "        'Non-parametric',\n",
    "        'O(1) - stores training data',\n",
    "        'O(n) - distance to all points', \n",
    "        'O(n) - stores all training data',\n",
    "        'k value, distance metric',\n",
    "        'Very sensitive - requires scaling',\n",
    "        'Cannot handle missing values',\n",
    "        'High - shows actual neighbors',\n",
    "        'No (can be modified for probabilities)',\n",
    "        'Complex, non-linear boundaries',\n",
    "        'Suffers significantly',\n",
    "        'High - affected by outliers',\n",
    "        'Small datasets, complex boundaries'\n",
    "    ],\n",
    "    'Naive Bayes': [\n",
    "        'Probabilistic/Eager Learning',\n",
    "        'Parametric',\n",
    "        'O(n) - calculates probabilities',\n",
    "        'O(1) - simple probability calculation',\n",
    "        'O(features) - stores probabilities',\n",
    "        'Smoothing parameter (alpha)',\n",
    "        'Generally robust to scaling',\n",
    "        'Can handle missing values naturally',\n",
    "        'Medium - shows feature probabilities', \n",
    "        'Yes - inherently probabilistic',\n",
    "        'Linear decision boundaries',\n",
    "        'Performs well in high dimensions',\n",
    "        'Low - robust to irrelevant features',\n",
    "        'Text classification, high dimensions'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "for i, row in comparison_df.iterrows():\n",
    "    print(f\"{row['Aspect']:30} | {row['K-Nearest Neighbors']:35} | {row['Naive Bayes']}\")\n",
    "\n",
    "# Performance comparison visualization\n",
    "print(\"\\nüìä PERFORMANCE VISUALIZATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('KNN vs Naive Bayes: Comprehensive Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Accuracy Comparison on Iris\n",
    "ax1 = axes[0, 0]\n",
    "models = ['KNN (best k)', 'Gaussian NB', 'Multinomial NB', 'Bernoulli NB']\n",
    "accuracies = [\n",
    "    best_accuracy,\n",
    "    iris_nb_results.get('Gaussian NB', {}).get('accuracy', 0),\n",
    "    iris_nb_results.get('Multinomial NB', {}).get('accuracy', 0),\n",
    "    iris_nb_results.get('Bernoulli NB', {}).get('accuracy', 0)\n",
    "]\n",
    "colors = ['steelblue', 'forestgreen', 'orange', 'purple']\n",
    "bars = ax1.bar(models, accuracies, color=colors, alpha=0.8)\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Accuracy Comparison on Iris Dataset')\n",
    "ax1.set_ylim(0, 1)\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    if acc > 0:\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{acc:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 2. Training Time Comparison\n",
    "ax2 = axes[0, 1]\n",
    "knn_train_time = 0.001  # Approximate for lazy learning\n",
    "nb_train_times = [iris_nb_results.get(model, {}).get('train_time', 0) \n",
    "                  for model in ['Gaussian NB', 'Multinomial NB', 'Bernoulli NB']]\n",
    "all_train_times = [knn_train_time] + nb_train_times\n",
    "\n",
    "bars = ax2.bar(models, all_train_times, color=colors, alpha=0.8)\n",
    "ax2.set_ylabel('Training Time (seconds)')\n",
    "ax2.set_title('Training Time Comparison')\n",
    "plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 3. Prediction Time Comparison  \n",
    "ax3 = axes[0, 2]\n",
    "knn_pred_time = 0.01  # Approximate\n",
    "nb_pred_times = [iris_nb_results.get(model, {}).get('predict_time', 0) \n",
    "                 for model in ['Gaussian NB', 'Multinomial NB', 'Bernoulli NB']]\n",
    "all_pred_times = [knn_pred_time] + nb_pred_times\n",
    "\n",
    "bars = ax3.bar(models, all_pred_times, color=colors, alpha=0.8)\n",
    "ax3.set_ylabel('Prediction Time (seconds)')\n",
    "ax3.set_title('Prediction Time Comparison')\n",
    "plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 4. Strengths and Weaknesses Radar Chart\n",
    "ax4 = axes[1, 0]\n",
    "categories = ['Accuracy', 'Speed', 'Interpretability', 'Scalability', 'Robustness']\n",
    "knn_scores = [0.9, 0.3, 0.9, 0.2, 0.4]  # Subjective scoring\n",
    "nb_scores = [0.8, 0.9, 0.7, 0.9, 0.8]\n",
    "\n",
    "angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Complete the circle\n",
    "knn_scores += knn_scores[:1]\n",
    "nb_scores += nb_scores[:1]\n",
    "\n",
    "ax4.plot(angles, knn_scores, 'o-', linewidth=2, label='KNN', color='steelblue')\n",
    "ax4.fill(angles, knn_scores, alpha=0.25, color='steelblue')\n",
    "ax4.plot(angles, nb_scores, 'o-', linewidth=2, label='Naive Bayes', color='forestgreen')\n",
    "ax4.fill(angles, nb_scores, alpha=0.25, color='forestgreen')\n",
    "\n",
    "ax4.set_xticks(angles[:-1])\n",
    "ax4.set_xticklabels(categories)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.set_title('Strengths Comparison (Subjective)')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "# 5. Dataset Suitability\n",
    "ax5 = axes[1, 1]\n",
    "scenarios = ['Small Dataset', 'Large Dataset', 'High Dimensions', 'Text Data', 'Noisy Data']\n",
    "knn_suitability = [0.9, 0.3, 0.2, 0.4, 0.3]\n",
    "nb_suitability = [0.7, 0.9, 0.9, 0.95, 0.8]\n",
    "\n",
    "x = np.arange(len(scenarios))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax5.bar(x - width/2, knn_suitability, width, label='KNN', color='steelblue', alpha=0.8)\n",
    "bars2 = ax5.bar(x + width/2, nb_suitability, width, label='Naive Bayes', color='forestgreen', alpha=0.8)\n",
    "\n",
    "ax5.set_ylabel('Suitability Score')\n",
    "ax5.set_title('Dataset Suitability Comparison')\n",
    "ax5.set_xticks(x)\n",
    "ax5.set_xticklabels(scenarios, rotation=45, ha='right')\n",
    "ax5.legend()\n",
    "ax5.set_ylim(0, 1)\n",
    "\n",
    "# 6. Decision Boundary Illustration\n",
    "ax6 = axes[1, 2]\n",
    "# Create a simple 2D example to show decision boundaries\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Generate 2D data for visualization\n",
    "class1_x = np.random.normal(2, 0.8, n_samples//2)\n",
    "class1_y = np.random.normal(2, 0.8, n_samples//2)\n",
    "class2_x = np.random.normal(6, 0.8, n_samples//2)\n",
    "class2_y = np.random.normal(6, 0.8, n_samples//2)\n",
    "\n",
    "ax6.scatter(class1_x, class1_y, c='blue', alpha=0.6, label='Class 1', s=50)\n",
    "ax6.scatter(class2_x, class2_y, c='red', alpha=0.6, label='Class 2', s=50)\n",
    "\n",
    "# Simple illustration of different decision boundaries\n",
    "x_line = np.linspace(0, 8, 100)\n",
    "# Linear boundary (Naive Bayes-like)\n",
    "y_linear = x_line  # Diagonal line\n",
    "ax6.plot(x_line, y_linear, 'g--', linewidth=3, label='NB-style (Linear)', alpha=0.8)\n",
    "\n",
    "# Non-linear boundary (KNN-like)\n",
    "y_nonlinear = 4 + 2*np.sin(x_line)\n",
    "ax6.plot(x_line, y_nonlinear, 'orange', linewidth=3, label='KNN-style (Complex)', alpha=0.8)\n",
    "\n",
    "ax6.set_xlabel('Feature 1')\n",
    "ax6.set_ylabel('Feature 2')\n",
    "ax6.set_title('Decision Boundary Styles')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.set_xlim(0, 8)\n",
    "ax6.set_ylim(0, 8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final recommendations\n",
    "print(\"\\nüéØ ALGORITHM SELECTION RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"üî∏ Choose KNN when:\")\n",
    "print(\"   ‚Ä¢ Small to medium dataset size\")\n",
    "print(\"   ‚Ä¢ Complex, non-linear decision boundaries expected\")\n",
    "print(\"   ‚Ä¢ High interpretability needed (see actual neighbors)\")\n",
    "print(\"   ‚Ä¢ Local patterns are important\")\n",
    "print(\"   ‚Ä¢ Sufficient computational resources for prediction\")\n",
    "\n",
    "print(\"\\nüî∏ Choose Naive Bayes when:\")\n",
    "print(\"   ‚Ä¢ Large datasets with many features\")\n",
    "print(\"   ‚Ä¢ Text classification or categorical data\")\n",
    "print(\"   ‚Ä¢ Fast prediction time is critical\")\n",
    "print(\"   ‚Ä¢ Limited computational resources\")\n",
    "print(\"   ‚Ä¢ Features are relatively independent\")\n",
    "print(\"   ‚Ä¢ Probabilistic outputs are needed\")\n",
    "\n",
    "print(\"\\nüî∏ Dataset Characteristics:\")\n",
    "print(\"   ‚Ä¢ Text/NLP tasks: Naive Bayes (especially Multinomial)\")\n",
    "print(\"   ‚Ä¢ Image classification: KNN (with proper features)\")\n",
    "print(\"   ‚Ä¢ Recommendation systems: KNN (collaborative filtering)\")\n",
    "print(\"   ‚Ä¢ Spam detection: Naive Bayes\")\n",
    "print(\"   ‚Ä¢ Medical diagnosis: Both (depends on data size)\")\n",
    "\n",
    "print(f\"\\n‚úÖ COMPARISON ANALYSIS COMPLETE!\")\n",
    "print(f\"Both algorithms have demonstrated strong performance in their respective domains.\")\n",
    "print(f\"The choice depends on your specific use case, data characteristics, and requirements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f183d3",
   "metadata": {},
   "source": [
    "# Part D: Bonus Tasks\n",
    "\n",
    "## Additional Implementations and Advanced Analysis\n",
    "\n",
    "This section covers bonus implementations including:\n",
    "1. Gaussian Naive Bayes on Iris dataset\n",
    "2. Advanced cross-validation analysis\n",
    "3. Feature importance and selection\n",
    "4. Performance optimization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cae980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Tasks Implementation\n",
    "\n",
    "print(\"üéÅ BONUS TASKS IMPLEMENTATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Bonus Task 1: Advanced Cross-Validation Analysis\n",
    "print(\"\\nüîÑ Bonus Task 1: Advanced Cross-Validation Analysis\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Define multiple scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Advanced CV for KNN on Iris\n",
    "print(\"üìä Advanced Cross-Validation for KNN (Iris Dataset)\")\n",
    "cv_folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "knn_cv_results = {}\n",
    "k_values_cv = [3, 5, 7, 9, 11]\n",
    "\n",
    "for k in k_values_cv:\n",
    "    knn_cv = KNeighborsClassifier(n_neighbors=k)\n",
    "    cv_results = cross_validate(\n",
    "        knn_cv, X_iris_scaled, y_iris, \n",
    "        cv=cv_folds, scoring=scoring,\n",
    "        return_train_score=True, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    knn_cv_results[k] = {\n",
    "        'test_accuracy': cv_results['test_accuracy'],\n",
    "        'test_precision': cv_results['test_precision'],\n",
    "        'test_recall': cv_results['test_recall'],\n",
    "        'test_f1': cv_results['test_f1'],\n",
    "        'train_accuracy': cv_results['train_accuracy'],\n",
    "        'fit_time': cv_results['fit_time'],\n",
    "        'score_time': cv_results['score_time']\n",
    "    }\n",
    "    \n",
    "    print(f\"k={k}: Accuracy={cv_results['test_accuracy'].mean():.4f} ¬± {cv_results['test_accuracy'].std():.4f}\")\n",
    "\n",
    "# Advanced CV for Naive Bayes on SMS\n",
    "print(\"\\nüì± Advanced Cross-Validation for Naive Bayes (SMS Dataset)\")\n",
    "nb_cv_results = {}\n",
    "\n",
    "# Use the best features from previous analysis\n",
    "best_vectorizer = tfidf_vectorizer if 'TF-IDF' in best_model_name else count_vectorizer\n",
    "X_sms_features = best_vectorizer.fit_transform(X_text)\n",
    "\n",
    "nb_models_cv = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'BernoulliNB': BernoulliNB(),\n",
    "    'ComplementNB': ComplementNB()\n",
    "}\n",
    "\n",
    "for name, model in nb_models_cv.items():\n",
    "    cv_results = cross_validate(\n",
    "        model, X_sms_features, y_text_encoded,\n",
    "        cv=cv_folds, scoring=scoring,\n",
    "        return_train_score=True, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    nb_cv_results[name] = cv_results\n",
    "    print(f\"{name}: F1={cv_results['test_f1'].mean():.4f} ¬± {cv_results['test_f1'].std():.4f}\")\n",
    "\n",
    "# Bonus Task 2: Feature Importance and Selection\n",
    "print(\"\\nüéØ Bonus Task 2: Feature Importance and Selection\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Feature selection for SMS dataset\n",
    "print(\"üìù Feature Selection for SMS Spam Detection\")\n",
    "\n",
    "# Chi-squared feature selection\n",
    "print(\"\\n1. Chi-squared Feature Selection:\")\n",
    "chi2_selector = SelectKBest(chi2, k=100)\n",
    "X_chi2 = chi2_selector.fit_transform(X_train_tfidf, y_train_text)\n",
    "chi2_scores = chi2_selector.scores_\n",
    "\n",
    "# Get selected features\n",
    "selected_features_chi2 = chi2_selector.get_support()\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "selected_feature_names = feature_names[selected_features_chi2]\n",
    "\n",
    "print(f\"Selected {len(selected_feature_names)} features out of {len(feature_names)}\")\n",
    "print(\"Top 10 features by Chi-squared score:\")\n",
    "top_chi2_indices = np.argsort(chi2_scores)[-10:][::-1]\n",
    "for i, idx in enumerate(top_chi2_indices, 1):\n",
    "    if selected_features_chi2[idx]:\n",
    "        print(f\"  {i:2d}. {feature_names[idx]:20} (œá¬≤ = {chi2_scores[idx]:.2f})\")\n",
    "\n",
    "# Mutual Information feature selection\n",
    "print(\"\\n2. Mutual Information Feature Selection:\")\n",
    "mi_selector = SelectKBest(mutual_info_classif, k=100)\n",
    "X_mi = mi_selector.fit_transform(X_train_tfidf, y_train_text)\n",
    "mi_scores = mi_selector.scores_\n",
    "\n",
    "selected_features_mi = mi_selector.get_support()\n",
    "print(f\"Selected {sum(selected_features_mi)} features by mutual information\")\n",
    "\n",
    "# Test performance with feature selection\n",
    "print(\"\\n3. Performance with Feature Selection:\")\n",
    "nb_feature_test = MultinomialNB()\n",
    "\n",
    "# Original features\n",
    "nb_feature_test.fit(X_train_tfidf, y_train_text)\n",
    "y_pred_original = nb_feature_test.predict(X_test_tfidf)\n",
    "f1_original = f1_score(y_test_text, y_pred_original)\n",
    "\n",
    "# Chi-squared selected features\n",
    "X_test_chi2 = chi2_selector.transform(X_test_tfidf)\n",
    "nb_feature_test.fit(X_chi2, y_train_text)\n",
    "y_pred_chi2 = nb_feature_test.predict(X_test_chi2)\n",
    "f1_chi2 = f1_score(y_test_text, y_pred_chi2)\n",
    "\n",
    "# MI selected features\n",
    "X_test_mi = mi_selector.transform(X_test_tfidf)\n",
    "nb_feature_test.fit(X_mi, y_train_text)\n",
    "y_pred_mi = nb_feature_test.predict(X_test_mi)\n",
    "f1_mi = f1_score(y_test_text, y_pred_mi)\n",
    "\n",
    "print(f\"Original features F1-score: {f1_original:.4f}\")\n",
    "print(f\"Chi-squared selection F1-score: {f1_chi2:.4f}\")\n",
    "print(f\"Mutual information selection F1-score: {f1_mi:.4f}\")\n",
    "\n",
    "# Bonus Task 3: Gaussian Naive Bayes on Iris with detailed analysis\n",
    "print(\"\\nüå∏ Bonus Task 3: Detailed Gaussian Naive Bayes Analysis on Iris\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Comprehensive Gaussian NB analysis\n",
    "gnb_detailed = GaussianNB()\n",
    "\n",
    "# Fit the model\n",
    "gnb_detailed.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "# Predictions and probabilities\n",
    "y_pred_gnb = gnb_detailed.predict(X_test_iris)\n",
    "y_pred_proba_gnb = gnb_detailed.predict_proba(X_test_iris)\n",
    "\n",
    "# Detailed metrics\n",
    "accuracy_gnb = accuracy_score(y_test_iris, y_pred_gnb)\n",
    "precision_gnb = precision_score(y_test_iris, y_pred_gnb, average='weighted')\n",
    "recall_gnb = recall_score(y_test_iris, y_pred_gnb, average='weighted')\n",
    "f1_gnb = f1_score(y_test_iris, y_pred_gnb, average='weighted')\n",
    "\n",
    "print(f\"Gaussian Naive Bayes Performance on Iris:\")\n",
    "print(f\"  Accuracy: {accuracy_gnb:.4f}\")\n",
    "print(f\"  Precision: {precision_gnb:.4f}\")\n",
    "print(f\"  Recall: {recall_gnb:.4f}\")\n",
    "print(f\"  F1-Score: {f1_gnb:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm_gnb = confusion_matrix(y_test_iris, y_pred_gnb)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_gnb)\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test_iris, y_pred_gnb, target_names=iris.target_names))\n",
    "\n",
    "# Feature statistics analysis\n",
    "print(f\"\\nüìä Feature Statistics by Class (Gaussian NB learns these):\")\n",
    "feature_names_iris = iris.feature_names\n",
    "\n",
    "for class_idx, class_name in enumerate(iris.target_names):\n",
    "    print(f\"\\n{class_name.upper()}:\")\n",
    "    class_mask = y_train_iris == class_idx\n",
    "    class_data = X_train_iris[class_mask]\n",
    "    \n",
    "    for feature_idx, feature_name in enumerate(feature_names_iris):\n",
    "        mean_val = class_data[:, feature_idx].mean()\n",
    "        std_val = class_data[:, feature_idx].std()\n",
    "        print(f\"  {feature_name:20}: Œº={mean_val:.3f}, œÉ={std_val:.3f}\")\n",
    "\n",
    "# Bonus Task 4: Performance Optimization and Scalability Analysis\n",
    "print(\"\\n‚ö° Bonus Task 4: Performance Optimization and Scalability Analysis\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "import time\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate datasets of different sizes\n",
    "dataset_sizes = [100, 500, 1000, 5000, 10000]\n",
    "performance_results = {'KNN': {}, 'NB': {}}\n",
    "\n",
    "print(\"üî¨ Scalability Analysis with Synthetic Datasets\")\n",
    "\n",
    "for size in dataset_sizes:\n",
    "    print(f\"\\nDataset size: {size} samples\")\n",
    "    \n",
    "    # Generate synthetic dataset\n",
    "    X_synthetic, y_synthetic = make_classification(\n",
    "        n_samples=size, n_features=20, n_informative=15,\n",
    "        n_redundant=5, n_classes=3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(\n",
    "        X_synthetic, y_synthetic, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # KNN Performance\n",
    "    knn_syn = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # Training time (KNN is lazy, so this is just storage)\n",
    "    start_time = time.time()\n",
    "    knn_syn.fit(X_train_syn, y_train_syn)\n",
    "    knn_train_time = time.time() - start_time\n",
    "    \n",
    "    # Prediction time\n",
    "    start_time = time.time()\n",
    "    y_pred_knn_syn = knn_syn.predict(X_test_syn)\n",
    "    knn_pred_time = time.time() - start_time\n",
    "    \n",
    "    knn_accuracy_syn = accuracy_score(y_test_syn, y_pred_knn_syn)\n",
    "    \n",
    "    # Naive Bayes Performance\n",
    "    nb_syn = GaussianNB()\n",
    "    \n",
    "    # Training time\n",
    "    start_time = time.time()\n",
    "    nb_syn.fit(X_train_syn, y_train_syn)\n",
    "    nb_train_time = time.time() - start_time\n",
    "    \n",
    "    # Prediction time\n",
    "    start_time = time.time()\n",
    "    y_pred_nb_syn = nb_syn.predict(X_test_syn)\n",
    "    nb_pred_time = time.time() - start_time\n",
    "    \n",
    "    nb_accuracy_syn = accuracy_score(y_test_syn, y_pred_nb_syn)\n",
    "    \n",
    "    # Store results\n",
    "    performance_results['KNN'][size] = {\n",
    "        'train_time': knn_train_time,\n",
    "        'pred_time': knn_pred_time,\n",
    "        'accuracy': knn_accuracy_syn\n",
    "    }\n",
    "    \n",
    "    performance_results['NB'][size] = {\n",
    "        'train_time': nb_train_time,\n",
    "        'pred_time': nb_pred_time,\n",
    "        'accuracy': nb_accuracy_syn\n",
    "    }\n",
    "    \n",
    "    print(f\"  KNN: Train={knn_train_time:.4f}s, Pred={knn_pred_time:.4f}s, Acc={knn_accuracy_syn:.4f}\")\n",
    "    print(f\"  NB:  Train={nb_train_time:.4f}s, Pred={nb_pred_time:.4f}s, Acc={nb_accuracy_syn:.4f}\")\n",
    "\n",
    "# Bonus Task 5: Advanced Visualization and Insights\n",
    "print(\"\\nüìä Bonus Task 5: Advanced Visualization and Insights\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create comprehensive bonus visualizations\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 18))\n",
    "fig.suptitle('Bonus Tasks: Advanced Analysis and Visualizations', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Cross-validation stability\n",
    "ax1 = axes[0, 0]\n",
    "for k in k_values_cv:\n",
    "    cv_scores = knn_cv_results[k]['test_accuracy']\n",
    "    ax1.plot([k]*len(cv_scores), cv_scores, 'o', alpha=0.6, label=f'k={k}')\n",
    "    ax1.plot(k, cv_scores.mean(), 's', markersize=10, color='red')\n",
    "\n",
    "ax1.set_xlabel('k value')\n",
    "ax1.set_ylabel('Cross-validation Accuracy')\n",
    "ax1.set_title('KNN Cross-Validation Stability')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Feature selection comparison\n",
    "ax2 = axes[0, 1]\n",
    "methods = ['Original', 'Chi-squared', 'Mutual Info']\n",
    "f1_scores_fs = [f1_original, f1_chi2, f1_mi]\n",
    "colors = ['blue', 'green', 'orange']\n",
    "bars = ax2.bar(methods, f1_scores_fs, color=colors, alpha=0.8)\n",
    "ax2.set_ylabel('F1-Score')\n",
    "ax2.set_title('Feature Selection Impact')\n",
    "for bar, score in zip(bars, f1_scores_fs):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Gaussian NB confusion matrix\n",
    "ax3 = axes[0, 2]\n",
    "sns.heatmap(cm_gnb, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names, ax=ax3)\n",
    "ax3.set_title('Gaussian NB Confusion Matrix (Iris)')\n",
    "ax3.set_ylabel('Actual')\n",
    "ax3.set_xlabel('Predicted')\n",
    "\n",
    "# 4. Scalability - Training Time\n",
    "ax4 = axes[1, 0]\n",
    "sizes = list(dataset_sizes)\n",
    "knn_train_times = [performance_results['KNN'][s]['train_time'] for s in sizes]\n",
    "nb_train_times = [performance_results['NB'][s]['train_time'] for s in sizes]\n",
    "\n",
    "ax4.plot(sizes, knn_train_times, 'o-', label='KNN', linewidth=2, markersize=8)\n",
    "ax4.plot(sizes, nb_train_times, 's-', label='Naive Bayes', linewidth=2, markersize=8)\n",
    "ax4.set_xlabel('Dataset Size')\n",
    "ax4.set_ylabel('Training Time (seconds)')\n",
    "ax4.set_title('Training Time Scalability')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Scalability - Prediction Time\n",
    "ax5 = axes[1, 1]\n",
    "knn_pred_times = [performance_results['KNN'][s]['pred_time'] for s in sizes]\n",
    "nb_pred_times = [performance_results['NB'][s]['pred_time'] for s in sizes]\n",
    "\n",
    "ax5.plot(sizes, knn_pred_times, 'o-', label='KNN', linewidth=2, markersize=8)\n",
    "ax5.plot(sizes, nb_pred_times, 's-', label='Naive Bayes', linewidth=2, markersize=8)\n",
    "ax5.set_xlabel('Dataset Size')\n",
    "ax5.set_ylabel('Prediction Time (seconds)')\n",
    "ax5.set_title('Prediction Time Scalability')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Feature importance (Chi-squared scores)\n",
    "ax6 = axes[1, 2]\n",
    "top_10_chi2 = np.argsort(chi2_scores)[-10:][::-1]\n",
    "top_features = [feature_names[i] for i in top_10_chi2]\n",
    "top_scores = [chi2_scores[i] for i in top_10_chi2]\n",
    "\n",
    "ax6.barh(range(len(top_features)), top_scores, color='green', alpha=0.7)\n",
    "ax6.set_yticks(range(len(top_features)))\n",
    "ax6.set_yticklabels(top_features)\n",
    "ax6.set_xlabel('Chi-squared Score')\n",
    "ax6.set_title('Top 10 Features (Chi-squared)')\n",
    "\n",
    "# 7. Cross-validation score distribution\n",
    "ax7 = axes[2, 0]\n",
    "all_cv_scores = []\n",
    "all_cv_labels = []\n",
    "\n",
    "for name, results in nb_cv_results.items():\n",
    "    all_cv_scores.extend(results['test_f1'])\n",
    "    all_cv_labels.extend([name] * len(results['test_f1']))\n",
    "\n",
    "import seaborn as sns\n",
    "sns.boxplot(x=all_cv_labels, y=all_cv_scores, ax=ax7)\n",
    "ax7.set_ylabel('F1-Score')\n",
    "ax7.set_title('NB Cross-Validation Score Distribution')\n",
    "ax7.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 8. Accuracy vs Dataset Size\n",
    "ax8 = axes[2, 1]\n",
    "knn_accuracies = [performance_results['KNN'][s]['accuracy'] for s in sizes]\n",
    "nb_accuracies = [performance_results['NB'][s]['accuracy'] for s in sizes]\n",
    "\n",
    "ax8.plot(sizes, knn_accuracies, 'o-', label='KNN', linewidth=2, markersize=8)\n",
    "ax8.plot(sizes, nb_accuracies, 's-', label='Naive Bayes', linewidth=2, markersize=8)\n",
    "ax8.set_xlabel('Dataset Size')\n",
    "ax8.set_ylabel('Accuracy')\n",
    "ax8.set_title('Accuracy vs Dataset Size')\n",
    "ax8.legend()\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Feature correlation with target (Iris)\n",
    "ax9 = axes[2, 2]\n",
    "iris_corr = []\n",
    "for i in range(X_iris_scaled.shape[1]):\n",
    "    corr = np.corrcoef(X_iris_scaled[:, i], y_iris)[0, 1]\n",
    "    iris_corr.append(abs(corr))\n",
    "\n",
    "ax9.bar(range(len(iris_corr)), iris_corr, color='purple', alpha=0.7)\n",
    "ax9.set_xticks(range(len(iris_corr)))\n",
    "ax9.set_xticklabels([name.split(' (')[0] for name in iris.feature_names], rotation=45)\n",
    "ax9.set_ylabel('Absolute Correlation with Target')\n",
    "ax9.set_title('Feature-Target Correlation (Iris)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final bonus summary\n",
    "print(\"\\nüéâ BONUS TASKS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(\"‚úÖ Advanced Cross-Validation: Completed with 10-fold stratified CV\")\n",
    "print(\"‚úÖ Feature Selection: Chi-squared and Mutual Information methods tested\")\n",
    "print(\"‚úÖ Gaussian NB Analysis: Detailed performance on Iris dataset\")\n",
    "print(\"‚úÖ Scalability Analysis: Performance tested on datasets up to 10,000 samples\")\n",
    "print(\"‚úÖ Advanced Visualizations: Comprehensive plots for all analyses\")\n",
    "\n",
    "print(f\"\\nüèÜ Key Insights from Bonus Tasks:\")\n",
    "print(f\"   ‚Ä¢ Feature selection can maintain performance with fewer features\")\n",
    "print(f\"   ‚Ä¢ Naive Bayes scales better than KNN for large datasets\")\n",
    "print(f\"   ‚Ä¢ Cross-validation shows consistent performance across folds\")\n",
    "print(f\"   ‚Ä¢ Gaussian NB performs excellently on Iris dataset\")\n",
    "print(f\"   ‚Ä¢ KNN prediction time grows linearly with dataset size\")\n",
    "\n",
    "print(f\"\\n‚ú® BONUS TASKS COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"All advanced analyses demonstrate the robustness and versatility of both algorithms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79788286",
   "metadata": {},
   "source": [
    "# Assignment Conclusion\n",
    "\n",
    "## Summary of Learning Outcomes\n",
    "\n",
    "This comprehensive assignment has successfully demonstrated the implementation, evaluation, and comparison of K-Nearest Neighbors and Naive Bayes algorithms across different datasets and scenarios.\n",
    "\n",
    "### Key Achievements:\n",
    "- ‚úÖ **Theoretical Understanding**: Comprehensive coverage of algorithm principles, mathematical foundations, and practical considerations\n",
    "- ‚úÖ **Practical Implementation**: Successful implementation of KNN on Iris dataset and multiple Naive Bayes variants on SMS spam dataset\n",
    "- ‚úÖ **Performance Analysis**: Detailed evaluation using multiple metrics including accuracy, precision, recall, F1-score, and AUC-ROC\n",
    "- ‚úÖ **Comparative Study**: Thorough comparison of algorithms across various dimensions including accuracy, scalability, and use cases\n",
    "- ‚úÖ **Advanced Techniques**: Implementation of cross-validation, hyperparameter tuning, feature selection, and performance optimization\n",
    "- ‚úÖ **Visualization**: Comprehensive plots and charts for better understanding of algorithm behavior and performance\n",
    "\n",
    "### Skills Demonstrated:\n",
    "1. **Data Preprocessing**: Text cleaning, vectorization, feature scaling, and data preparation\n",
    "2. **Model Implementation**: Proper use of scikit-learn classifiers with appropriate parameters\n",
    "3. **Evaluation Methodology**: Cross-validation, confusion matrices, classification reports, and ROC analysis\n",
    "4. **Comparative Analysis**: Systematic comparison of different algorithms and their variants\n",
    "5. **Performance Optimization**: Hyperparameter tuning and feature selection techniques\n",
    "6. **Visualization**: Creating informative plots for data exploration and result presentation\n",
    "\n",
    "This assignment provides a solid foundation for understanding and applying these fundamental machine learning algorithms in real-world scenarios."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
